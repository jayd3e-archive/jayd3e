-- MySQL dump 10.13  Distrib 5.1.49, for debian-linux-gnu (i686)
--
-- Host: localhost    Database: jayd3e_db
-- ------------------------------------------------------
-- Server version	5.1.49-1ubuntu8.1

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `auth_group`
--

DROP TABLE IF EXISTS `auth_group`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_group` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(80) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `name` (`name`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_group`
--

LOCK TABLES `auth_group` WRITE;
/*!40000 ALTER TABLE `auth_group` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_group` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_group_permissions`
--

DROP TABLE IF EXISTS `auth_group_permissions`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_group_permissions` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `group_id` int(11) NOT NULL,
  `permission_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `group_id` (`group_id`,`permission_id`),
  KEY `auth_group_permissions_425ae3c4` (`group_id`),
  KEY `auth_group_permissions_1e014c8f` (`permission_id`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_group_permissions`
--

LOCK TABLES `auth_group_permissions` WRITE;
/*!40000 ALTER TABLE `auth_group_permissions` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_group_permissions` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_message`
--

DROP TABLE IF EXISTS `auth_message`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_message` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `message` longtext NOT NULL,
  PRIMARY KEY (`id`),
  KEY `auth_message_403f60f` (`user_id`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_message`
--

LOCK TABLES `auth_message` WRITE;
/*!40000 ALTER TABLE `auth_message` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_message` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_permission`
--

DROP TABLE IF EXISTS `auth_permission`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_permission` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(50) NOT NULL,
  `content_type_id` int(11) NOT NULL,
  `codename` varchar(100) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `content_type_id` (`content_type_id`,`codename`),
  KEY `auth_permission_1bb8f392` (`content_type_id`)
) ENGINE=MyISAM AUTO_INCREMENT=25 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_permission`
--

LOCK TABLES `auth_permission` WRITE;
/*!40000 ALTER TABLE `auth_permission` DISABLE KEYS */;
INSERT INTO `auth_permission` VALUES (1,'Can add permission',1,'add_permission'),(2,'Can change permission',1,'change_permission'),(3,'Can delete permission',1,'delete_permission'),(4,'Can add group',2,'add_group'),(5,'Can change group',2,'change_group'),(6,'Can delete group',2,'delete_group'),(7,'Can add user',3,'add_user'),(8,'Can change user',3,'change_user'),(9,'Can delete user',3,'delete_user'),(10,'Can add message',4,'add_message'),(11,'Can change message',4,'change_message'),(12,'Can delete message',4,'delete_message'),(13,'Can add content type',5,'add_contenttype'),(14,'Can change content type',5,'change_contenttype'),(15,'Can delete content type',5,'delete_contenttype'),(16,'Can add session',6,'add_session'),(17,'Can change session',6,'change_session'),(18,'Can delete session',6,'delete_session'),(19,'Can add site',7,'add_site'),(20,'Can change site',7,'change_site'),(21,'Can delete site',7,'delete_site'),(22,'Can add log entry',8,'add_logentry'),(23,'Can change log entry',8,'change_logentry'),(24,'Can delete log entry',8,'delete_logentry');
/*!40000 ALTER TABLE `auth_permission` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user`
--

DROP TABLE IF EXISTS `auth_user`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(30) NOT NULL,
  `first_name` varchar(30) NOT NULL,
  `last_name` varchar(30) NOT NULL,
  `email` varchar(75) NOT NULL,
  `password` varchar(128) NOT NULL,
  `is_staff` tinyint(1) NOT NULL,
  `is_active` tinyint(1) NOT NULL,
  `is_superuser` tinyint(1) NOT NULL,
  `last_login` datetime NOT NULL,
  `date_joined` datetime NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `username` (`username`)
) ENGINE=MyISAM AUTO_INCREMENT=2 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user`
--

LOCK TABLES `auth_user` WRITE;
/*!40000 ALTER TABLE `auth_user` DISABLE KEYS */;
INSERT INTO `auth_user` VALUES (1,'jayd3e','','','jd.dallago@gmail.com','sha1$4dee2$80e327c54222c381f76ae1aac1e9b0d16bec6f00',1,1,1,'2011-10-11 16:22:11','2011-10-11 16:22:11');
/*!40000 ALTER TABLE `auth_user` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user_groups`
--

DROP TABLE IF EXISTS `auth_user_groups`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_user_groups` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `group_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `user_id` (`user_id`,`group_id`),
  KEY `auth_user_groups_403f60f` (`user_id`),
  KEY `auth_user_groups_425ae3c4` (`group_id`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user_groups`
--

LOCK TABLES `auth_user_groups` WRITE;
/*!40000 ALTER TABLE `auth_user_groups` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_user_groups` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `auth_user_user_permissions`
--

DROP TABLE IF EXISTS `auth_user_user_permissions`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `auth_user_user_permissions` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `permission_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `user_id` (`user_id`,`permission_id`),
  KEY `auth_user_user_permissions_403f60f` (`user_id`),
  KEY `auth_user_user_permissions_1e014c8f` (`permission_id`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `auth_user_user_permissions`
--

LOCK TABLES `auth_user_user_permissions` WRITE;
/*!40000 ALTER TABLE `auth_user_user_permissions` DISABLE KEYS */;
/*!40000 ALTER TABLE `auth_user_user_permissions` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_admin_log`
--

DROP TABLE IF EXISTS `django_admin_log`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `django_admin_log` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `action_time` datetime NOT NULL,
  `user_id` int(11) NOT NULL,
  `content_type_id` int(11) DEFAULT NULL,
  `object_id` longtext,
  `object_repr` varchar(200) NOT NULL,
  `action_flag` smallint(5) unsigned NOT NULL,
  `change_message` longtext NOT NULL,
  PRIMARY KEY (`id`),
  KEY `django_admin_log_403f60f` (`user_id`),
  KEY `django_admin_log_1bb8f392` (`content_type_id`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_admin_log`
--

LOCK TABLES `django_admin_log` WRITE;
/*!40000 ALTER TABLE `django_admin_log` DISABLE KEYS */;
/*!40000 ALTER TABLE `django_admin_log` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_content_type`
--

DROP TABLE IF EXISTS `django_content_type`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `django_content_type` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(100) NOT NULL,
  `app_label` varchar(100) NOT NULL,
  `model` varchar(100) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `app_label` (`app_label`,`model`)
) ENGINE=MyISAM AUTO_INCREMENT=9 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_content_type`
--

LOCK TABLES `django_content_type` WRITE;
/*!40000 ALTER TABLE `django_content_type` DISABLE KEYS */;
INSERT INTO `django_content_type` VALUES (1,'permission','auth','permission'),(2,'group','auth','group'),(3,'user','auth','user'),(4,'message','auth','message'),(5,'content type','contenttypes','contenttype'),(6,'session','sessions','session'),(7,'site','sites','site'),(8,'log entry','admin','logentry');
/*!40000 ALTER TABLE `django_content_type` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_session`
--

DROP TABLE IF EXISTS `django_session`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `django_session` (
  `session_key` varchar(40) NOT NULL,
  `session_data` longtext NOT NULL,
  `expire_date` datetime NOT NULL,
  PRIMARY KEY (`session_key`),
  KEY `django_session_3da3d3d8` (`expire_date`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_session`
--

LOCK TABLES `django_session` WRITE;
/*!40000 ALTER TABLE `django_session` DISABLE KEYS */;
INSERT INTO `django_session` VALUES ('29c777c38aaa8510a2fdfe296a62a500','NWMxNDdkOWNhMjliYjYxYWEyNzZlMDAzZDk1NTEzZTYwMjE3YzAwNzqAAn1xAVUKdGVzdGNvb2tp\nZXECVQZ3b3JrZWRxA3Mu\n','2011-10-25 16:31:45');
/*!40000 ALTER TABLE `django_session` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `django_site`
--

DROP TABLE IF EXISTS `django_site`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `django_site` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `domain` varchar(100) NOT NULL,
  `name` varchar(50) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=MyISAM AUTO_INCREMENT=2 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `django_site`
--

LOCK TABLES `django_site` WRITE;
/*!40000 ALTER TABLE `django_site` DISABLE KEYS */;
INSERT INTO `django_site` VALUES (1,'example.com','example.com');
/*!40000 ALTER TABLE `django_site` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `posts`
--

DROP TABLE IF EXISTS `posts`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `posts` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(100) DEFAULT NULL,
  `body` varchar(20000) DEFAULT NULL,
  `date` date DEFAULT NULL,
  `created` datetime DEFAULT NULL,
  `change_time` datetime DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=34 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `posts`
--

LOCK TABLES `posts` WRITE;
/*!40000 ALTER TABLE `posts` DISABLE KEYS */;
INSERT INTO `posts` VALUES (5,'GSOC Application - Python Software Foundation','I have been a part of the Pylons Project community for about four months now.  From the time that I have spent with the community, I have decided that porting Pyramid and its dependencies to Python 3 is one of our immediate concerns.  This entails modifying the Pyramid source to be compatible with Python versions 2.5, 2.6, 2.7 and 3.2.  This is by no means a small task, but after consulting a few GSOC mentors in our community, I have determined that it is a project that I could significantly help with.  Not only would it be a meaningful contribution to the community, it would also notably improve my understanding of how the framework works at a lower level and provide a great deal of insight into the Python 2 to 3 conversion process.\r\n\r\n##Milestones\r\nThe nice thing about this project is that its progress can be monitored easily, as it consists of a number of smaller ports, which will eventually make it possible to work on porting the framework as a whole to Python 3.\r\n\r\n###Start of Program (May 24)\r\nDuring the initial stages of the program, I plan on spending most of my time studying the Pyramid code base.  I think a solid understanding of how the framework\'s code, as well as the code of its dependencies, actually works is necessary for effectively porting it.  I would also like to look into how one actually goes about porting an application to Python 3.  There have already been a number of books written on the subject of porting pre-existing applications, and I plan on consulting a number of these resources and then forming an approach to complete this project, as I have not had a great deal of experience with porting applications between language versions.\r\n\r\nAfter I have an adequate foundation for the task, I will start with some of the smaller dependencies of Pyramid.  To continue to uphold the Pylons Project\'s standards, I plan on making sure each dependency has 100% test coverage, before I begin porting.  After gaining 100% test coverage, I will use the tactics outlined in the previously mentioned books/articles to begin the conversion process.\r\n\r\n###Midterm Evaluation (July 12)\r\nBy the midterm evaluation, I would like to have about a quarter of Pyramid\'s dependencies fully covered by tests, and ported to Python 3.\r\n\r\n###Final Evaluation (Aug 16)\r\nBy the final evaluation, I would like to have about half of Pyramid\'s dependencies fully covered by tests, and ported to Python 3.  This seems like a realistic goal, especially if I have help from a few other students.\r\n\r\n*These predictions are very optimistic, but could be possible if all things go as planned and I have some additional help.\r\n\r\n##About Me\r\nMy name is Joe Dallago, and I am a freshman at the University of Iowa.  I fell in love with the art of programming when I was 13, and I have been addicted ever since.  I have experimented in a number of areas of computing, but for the past four years or so, I have been more or less focused on improving my abilities as a web developer.  Most of my experience in web development resides in the PHP world.  As a beginner, I found that PHP web development was far easier to understand than Python development.  I worked with a variety of different PHP frameworks, most notably CakePHP.  During the four year span that I used PHP I learned a vast amount of information about the web world, and later used it to create web-based integration tools at my internship for Rockwell Collins(Jan. 2009 - Present), which I very much enjoy.  As I became more confident in my skills, I decided to try out Python web development, and I don\'t plan on going back.  I really enjoy writing Python as a language, and love the community.  I have been closely following the Pylons Project community, since I started my transition from PHP to Python about four months ago, and I think it is important that I start contributing to a community that has already provided me with so much.\r\n\r\nI have already participated a few times in the Pyramid community.  I made some alterations to the documentation for a terminology change(https://github.com/Pylons/pyramid/commit/758464303c00de745672d6c3e27566e3bc52859e).  I also helped to increase unit test coverage for WebOb at  Pycon sprint, before porting it Python 3, which can be found here https://bitbucket.org/chrism/webob-py3k/changesets/4f08e9b3f373.  My username for both sites is \'jayd3e\'.\r\n\r\n##Contact Info\r\nName: Joe Dallago  \r\nBlog: jayd3e.com  \r\nEmail: jd.dallago@gmail.com  \r\nPhone: 319-213-5077  \r\nPostal Address: 916 S Van Buren St  \r\nCity, State, Zip, Country:  Iowa City, IA 52440 US  ','2011-04-02','2011-04-02 18:47:48','2011-06-21 10:58:29'),(7,'StudentUnderground Project - Status Update','So for the last 4 months or so I have been developing an idea for a student collaboration site for the U of I(initially).  Students would essentially go to this proposed site, register, join a network(an entity similar to a Facebook network), join one or multiple groups(an entity similar to a Facebook group), and then monitor/contribute to the assignments connected with these groups.  These groups are powerful b/c they don\'t necessarily have to be representative of the classes in a school/university, they could simply represent a small group of friends who want to share answers with each other, or a study group. So your registered and your user is connect to a few groups, now what?  Well now you need to add some content, or the assignments, for other students to collaborate on.  As students receive homework, they would create an assignment on the site that corresponds with an article of homework.  Each assignment acts as its own separate wiki-like page, where students can share answers to assignments, as well as how they arrived at those answers.','2011-04-18','2011-04-18 23:00:28','2011-04-22 15:40:03'),(8,'GSOC Log - Entry #1','I have decided to start a daily(hopefully) log of my GSOC experience.  This will help my mentors stay updated with my work, as well as help me document the pieces of information that I deem important to remember.  \r\n\r\n###What I Learned-\r\nSo today I started looking into how to go about porting translationstring, one of Pyramid\'s dependencies, to Python 3.  TranslationString is a module that Pyramid uses for i18n(internationalization) and l10n(localization).  As defined in the Pyramid documentation:  *Internationalization (i18n) is the act of creating software with a user interface that can potentially be displayed in more than one language or cultural context. Localization (l10n) is the process of displaying the user interface of an internationalized application in a particular language or cultural context.*  I also learned the distinction between __new__() and __init__().  __new__() is used when you need to control the creation of a new instance of a class(you could even return a different class if you wanted, and __init__() initializes a new class, sets member variables/functions and such.\r\n\r\n###Project Progess-\r\nI didn\'t feel ready to actually start making changes to the code quite yet.  I did run 2to3 to see how code generation works, and I also read through the code to fully understand it.  It isn\'t a very long file, so I don\'t anticipate it taking long after I understand how to actually start porting.  I just received Lennart Regebro\'s book [Porting to Python 3](http://python3porting.com/), so I plan on reading that tomorrow during the day, and I should have a good idea of what I am doing by tomorrow night, so I can acutally start editing the code.  It is also worth noting that translationstring alrady has 100% test coverage.','2011-05-24','2011-05-24 02:58:00','2011-05-24 02:59:05'),(9,'Lennart\'s Book','So I would like to take some time to go through some of the main things I learned from Lennart\'s book.  This is a gross over simplification of everything so if you are reading this thinking you can get by with this alone, you can\'t.  I simply wanted to make sure that I documented the major concepts that I took away from the book for my own reference.  The following is more or less the footnotes I took while reading the book.\r\n\r\nPorting Methodologies\r\n---------------------\r\n1. Python 3 Only(easy) -  Convert your code to Python 3 with the 2to3 tool, fix any other runtime/semantic errors, and clean up the final version.  Relinquish all support for Python 2.\r\n2. Maintain Python 2 and 3 Version -  Port your code to Python 3, but continue to maintain your Python 2 code.  MAJOR DISADVANTAGE:  Every change has to be made in two places.\r\n3. Use 2to3 or 3to2- Maintain your code base in either Python 3 or 2, and then convert it using one of the aforementioned scripts each time you make changes.\r\n3. Use Distribution Tools and 2to3 to Convert Code -  The idea behind this methodology, is that you should only have to actually convert your code during the distribution phase.  A person downloads your package, and the package is converted to match the Python they\'re using.\r\n4. Alter Your Code to Support Both Version - This entails altering your code base to run under BOTH Python 2 and 3, using only one branch.  The use of 2to3 will only get you so far in this case, and is mainly used for understanding purposes and to eliminate grunt work.  This is the method that the Pylons Project has decided will be appropriate for the porting of Pyramid, as it will allow Pyramid to easily transition to Python 3 through the use of the backported modules and porting libraries.\r\n\r\nPre-Port Checklist\r\n------------------\r\nIn Chapter 2 of the book, he discusses some helpful ways to prepare a code base to Python 3, so I decided to write a quick checklist for myself.\r\n\r\n+ Have 100% test coverage, according to the Pylons Project\'s policy.  It is far easier to port to Py3, if you are able to run all of your code under different versions of Python with little effort.\r\n+ Get everything running under Python 2.6 and 2.7.  As the last two version before 3.0, I think this is a solid starting point for porting to 3.0.  Due to the fact that Pyramid already support > 2.5, this is a non-issue.\r\n+ Replace all \"with\" and \"as\" keywords(just postpend them with an underscore).  \r\n+ Get rid of all string exceptions.  Python 2.6 allows them to be caught, but not raised.\r\n+ Run your code using the -3 flag.  This will notify you of possible conflicts with Python 3.\r\n+ Add the // operator to all uses of integer division.  In python 3, the division symbol(/) always does \"true division.\"  The ability to import Python3-like division by doing a \"from \\_\\_future\\_\\_ import division\" pretty much makes this problem a non-issue.\r\n+ Separate binary data and strings.  In Python 3, textual data(not exclusively textual though) is separated into two datatypes, \"bytes\" and \"strings.\"\r\n+ Use file mode flags(\'t\' and \'b\') to distinguish between binary and text.  Always.\r\n+ There are two types of sorting, one that compares two values and returns which way each element is to be moved in the data set(cmp), and the other stores an index of where a value is in the data set(key).  Use \'key\' sorting for most use cases in Python 3, it\'s faster, and is the only method that is supported in Python 3.\r\n+ The \\_\\_cmp\\_\\_() function is no longer available(very few things with the name \"cmp\" are available in Py3), so use the \"rich comparison operators.\"\r\n+ Lennart mentions that you should start using the iterator versions of keys(), values(), and items() on dictionaries, so 2to3 will know when a list isn\'t required as a return value; however, since the Pylons Project has decided to support 2 and 3 simultaneously, I think I will just be aware of how 2to3 handles the usage of these three functions and continue to use the non-iterator functions for Python 2.5, 2.6, and 2.7.\r\n+ Remove all references to Py3 deprecated modules.\r\n\r\n2to3\r\n----\r\n2to3 is actually a framework of a number of units called \"fixers.\"  Fixers make very specific changes to a line fo code, such as changing the \"except Exception, exception\" syntax to \"except Exception as exception.\"  Users can add their own fixers, as well as use the predefined ones that come with 2to3.  He mentions a few different options for 2to3.  The only ones I will be using are:\r\n\r\n    # Converts the current directory and writes the \r\n    # changes made to each file, as opposed to keeping\r\n    # backups of the originals\r\n    2to3 -w .  \r\n    \r\n    # The -f flag specifies a specific fixer to apply.  \r\n    # The \'all\' fixer includes all of the fixers included \r\n    # with lib2to3\r\n    2to3 -f all -f buffer . \r\n\r\nSpecific Strategies Needed for Supporting 2 AND 3\r\n----------------------------------------------\r\nMost of the changes you will encounter, will be solved with 2to3, but there are a few special cases that must be accounted for:\r\n\r\n+ PROBLEM: The print function syntax has changed.  SOLUTION: Use print(\"\") for printing basic text, use \"from __future__ import print_function\"(only usable in > 2.6, so not applicable to my project), or use a custom print function that uses sys.stdout.write(), which is included in six.\r\n+ PROBLEM:  The syntax for Exceptions has changed.  SOLUTION:  There wasn\'t a clear way of dealing with this in the book.  Basically, there is one accepted syntax for each version.\r\n+ PROBLEM: Exceptions are not iterable. SOLUTION:  Use e.args in Python 3.\r\n+ PROBLEM: The long and int datatypes have been merged. SOLUTION:  In Python 3, simply set the long datatype equal to the integer datatype.\r\n+ PROBLEM: The return type of a number of function has been changed from unicode to str(text data) and from str to bytes(binary data).  SOLUTION:  Use six :).  All of the solutions to these problems involve writing your own unicode and binary literal functions, which are included in six.  The one solution I didn\'t mentioned was using \"from __future__ import unicode_literals,\" because it is only usable in version > 2.6, my project requirement states that Pyramid must support 2.5.\r\n\r\nGeneral Thoughts\r\n----------------\r\nOverall it was a very informative book for such a short read.  I really only mentioned the parts of the book that applied to my project and left out the great majority of information, so I definitely recommend reading the full thing.  The reference section in the back that gives a comprehensive list of all of the changes made between 2 and 3 is worth the price alone.','2011-05-26','2011-05-26 23:56:31','2011-05-27 09:56:49'),(10,'First Commit - Impressions','I made my first commit to translationstring tonight, and just wanted to jot down some quick notes.  First of all, [Six](http://packages.python.org/six/) rocks.  Most of the complications that arise when you are trying to make a codebase compatible with Python 2 and 3, are easily vanquished via [Six](http://packages.python.org/six/).  I would also like to mention that after using 2to3 tonight, I have come to the conclusion that it obviously won\'t be incredibly useful for my needs, as I need to provide support for Python 2 as well, but I plan on hacking the lib2to3 framework by creating fixtures to replace some of the more obvious changes between the versions(unicode/byte literals, unicode/basestring/str classes, and exceptions) with their [Six](http://packages.python.org/six/) equivalents.','2011-05-27','2011-05-27 02:19:08','2011-05-27 02:20:36'),(11,'Twelve - An Extension of 2to3','Today I extended lib2to3 to meet our needs for porting Pyramid and its dependencies.  I simply created a new script(called twelve, b/c 2 * 6 = 12) that points to a different fixer directory.  In that fixer directory, I wrote(using the standard fixers from 2to3 as guides) four fixers that convert various Python2-like syntax to their respective Six counterparts.  Currently, twelve makes it possible to:\r\n\r\n+ Convert unicode objects, classes, and functions to the \'text_type\' Six constant.\r\n+ Convert unichr objects to chr.\r\n+ Convert basestring objects to the \'string_types\' Six constant.\r\n+ Convert unicode literals(u\'\') to the unicode literal Six function(u()).\r\n\r\nThese are the only changes I have really made thus far on translationstring, so I thought I would only write fixers for the problems I have encountered.  I also properly setup my fork of the translationstring package, which is located [here](https://github.com/jayd3e/translationstring).  Twelve can be found [here](https://github.com/jayd3e/Twelve/tree/master/twelve).  Keep in mind, it is very primitive right now.  I hope that we will be able to create a number of other fixers for Twelve as we continue to work through this project.  I plan on writing a quick guide on how to go about creating fixers in Twelve/2to3(b/c fixers are written the same in both) tomorrow.','2011-05-28','2011-05-28 02:46:32','2011-05-28 02:51:55'),(12,'Completion of Translationstring','Today I finished translationstring.  I had to pull in the Translations class from Babel to do so, but it all worked out in the end.  What I did was simply \"copied & pasted\" the Translations class from babel.support, converted the parts that were used to Python 3, and then deleted everything that wasn\'t being run, by using the information that was spit out by the coverage tests.\r\n\r\nAfter I completed translationstring, I started working on porting WebOb.  First, I ran Twelve(my extension of 2to3), to convert the easy syntax changes to six-style syntax.  I checked all of the changes made to assure myself that they were all meaningful changes, and then I began studying how WebOb does exactly what it does.','2011-06-01','2011-06-01 01:12:33','2011-06-01 01:12:33'),(13,'Making Progress with WebOb','Last night I created two more fixers for Twelve, as I encountered two new problems in WebOb.  The first was a simple import fixer that changes \'from rfc822\' and \'import rfc822\' to \'from email.utils\' and \'import email.utils.\'  Judging from their APIs in the Python documentation, I have come to the conclusion that both of these packages are identical as far as WebOb is concerned, so the simple change should not be an issue.  I found a place in the PyDocs that even mentioned that email.utils should be used in all version after v2.2, as rfc822 is deprecated in Py3.\r\n\r\nThe second fixer is slightly more complicated.  I encountered quite a few errors(around 20-30) that dealt with the syntax changes in Py3 for raising exceptions.  Instead of the old implicit tuple method(i.e. raise E, V, T), you now have to write it in this format:  raise E(V).with_traceback(T).  This really isn\'t that big of a deal when E and V are defined, b/c it in both of those cases, the standard \'E(V)\' syntax works in all versions of Python; however, when you need to defined a traceback, you start to run into some issues.  Because Python2 doesn\'t support the with_trackback(T) method.  In order to deal with this inconsistency, the \'six\' library has created a function that treats exceptions differently between the two versions, called \'reraise().\'  The Twelve fixer I created replaces all instances of \'raise E, V, T\' with \'six.reraise(E, V, T).\'  Tonight, I would like to modify the fixer to make some cool code style decisions for you.  For example, I would like it to change ever occurrence of \'six.reraise(Exception())\' to simple \'six.reraise(Exception),\' as they are the same thing.  After that is complete, I plan on running Twelve on WebOb again, committing the resulting code, and begin fixing new errors.  This next commit should be a pretty large commit, b/c like I said out of the 120-130 errors that were thrown during tests, about 20-30 were \'raise\' errors.\r\n\r\nIf you would like to track my progress with WebOb, the repo is located [here](https://bitbucket.org/jayd3e/webob-py3).','2011-06-06','2011-06-06 17:06:17','2011-06-07 00:31:06'),(14,'TranslationString done and some further improvements to WebOb...','So I think TranslationString has finally reached completion.  About a week ago, Chris brought it to my attention that I resorted to monkey patching a module or two at import time in a few files.  I\'m glad that I made this mistake, b/c I actually was never fully aware of what monkey patching was exactly.  I heard it quite a few times at PyCon, as it seemed to be a pretty popular mistake, but I never really gained a full understanding of what it meant to \"monkey patch\" something.  I always find that I learn best by doing, so it makes sense that I finally learned what monkey patching was by making the mistake on my own.  I have now corrected all of the instances of monkey patching in my code, and have submitted another pull request with the correct commit range.\r\n\r\nI also did some more work on WebOb today.  I am finally beginning to understand exactly how much time it\'s going to take to port this code base.  I hope that I can get it done in the next two weeks, so I can start porting another package before the first evaluation period.  Enough about time management, let\'s get into the details.  I ran into two major errors today.  The first was an issue was the result of the removal of the \'iteritems()\' function of the dict class.  I couldn\'t find a easy way to use my Twelve library to do the work for me, so I resulted to using a try/except block, wherever the \'iteritems\' function was used, to catch an AttributeError, as mentioned in Lennart\'s book.  The second issue is with the six.reraise() function.  It seems that two arguments must be passed into this function, while I was under the impression that only one was needed(the exception).  So this means that Twelve is actually causing errors in this case.  I have e-mailed the creator of six to pick his brain on this issue.  ','2011-06-13','2011-06-13 00:18:00','2011-06-13 00:18:00'),(15,'Fixed a fixer(ironic, I know) and continued on WebOb','So if you remember from my last post, I remarked on how I was running into issues with the \'raise\' command between the two versions of Python.  In Python 2, you can use the ugly looking implicit tuple syntax that looks like something along the lines of \'raise E, V, T\', where \'E\' is the exception, \'V\' is the argument for the exception, and \'T\' is a traceback function.  While, in Python 3 they have removed the implicit tuple syntax, for the cleaner \'raise E(V).with_traceback(T).\'  The way I handled this problem in Twelve previously was to simply change all occurrences of \'raise E, V, T\' with the \'six.reraise\' function, which turned into something like this \'six.reraise(E, V, T).\'  This worked out great for all of the situations where a raise statement required all three elements(an exception, an argument, and a traceback), but as it turns out six.reraise would throw an exception if it only received a single argument.  I e-mailed the creator of six, and he said that this was done deliberately, as \'raise E(V)\' is an accepted syntax in all versions of Python.  So I decided that I would change my Twelve library to make the following conversions:\r\n\r\n    # raise E  -->  raise E\r\n    # raise E(V)  --> raise E(V)\r\n    # raise E, V  --> raise E(V)\r\n    # raise E, V, T --> six.reraise(E, V, T)\r\n\r\nThe last conversion only happens rarely.\r\n\r\nLast night, I was able to reverse all of the incorrect changes that were made by Twelve previously, due to this mistake.  I would also like to note that I discovered this issue after the six.reraise() function began to throw exceptions in the tests, and I didn\'t get a chance last night to double check that my alterations solved the problem, although I am almost positive that they did.  I will run the tests again later tonight, and continue to go through my development cycle, which has become similar to the following:\r\n\r\n1.  Run tests.\r\n2.  Focus on a specific exception thrown during run-time.\r\n3.  Consider if a Twelve fixer can be written to solve all instances of this problem(in other words, check to see  if the solution to the problem will require changes to one or multiple lines of code) in one fell swoop.\r\n4.  Either write a fixer to solve the problem, or go through the code and fix the exception on a case by case basis.\r\n5.  Run the tests again to verify that all of the exceptions related to the problem are gone.\r\n6.  Commit and push.','2011-06-15','2011-06-15 13:20:14','2011-06-15 13:22:35'),(16,'More progress on WebOb!','So I have been kind of putting off writing this blog post, as I knew that I would have a lot to report about and I was not exactly ecstatic to type a wall of text, but I have finally gotten around to it.  So here is the low down.  I put aside my usual steady GSOC work schedule, and went on an all out porting sprint last Saturday in order to fix as many exceptions as possible.  My goal was to get to a point where I was only receiving test assertion failures, as opposed to exceptions.  Unfortunately, I didn\'t really get close to this goal(it was an unrealistic goal in hindsight), but I did get a great deal of work done.  I would like to give a brief summary(in commit log form) of all of the small changes I made, and then give a brief overview of where I am in the project.  So here it goes:\r\n\r\n###Saturday - June 18th\r\n+  Created a fixer to change all of \'print()\' statements in WebOb to the six library equivalent(the six.print_() function).  This wasn\'t very hard to do at all, and it eliminated about 10 exceptions of the 200 or so that I started with.\r\n+  The \'iteritems\' member of the dict object no longer exists in Python 3, b/c dict.items() returns an iterator by default.  In order to keep Python 2 compatibility, I had to simply add a try/except block that would catch an AttributeError exception in Py3 and call the appropriate member function(dict.items()).\r\n+  In WebOb\'s response object, there is a function called header_getter() that does exactly what its name implies, it retrieves a specific header variable and stores it in the correct encoding.  With all of the data type changes that are present in Python 3, I had to amend this function to make sure that it was returning a native string variable(as is defined in PEP 3333).\r\n+  Fixed all instances of \'except Exception, e\' with \'except Exception as e\'.\r\n\r\nSo by the end of the day, I had about 150 exceptions and 11 failures, which really wasn\'t bad for one day.  I plan on working for most of the evening tonight to get rid of even more.  As previously mentioned, my plan is the get WebOb to a point, where no exceptions are thrown in Py3, and then I can start working on semantic errors in Py3.  From there, I will then run it in each of the older versions, fixing errors as I go, and eventually get it to pass all tests in each version.\r\n\r\nP.S. - Check out my blog\'s new look!  I plan on using the Twitter API to display my current tweet in that shoutbox above ^^.  A limited amount of posts on the index page and archives are coming soon...\r\n','2011-06-21','2011-06-21 10:56:04','2011-06-21 11:02:55'),(17,'Comparison of Migration Strategies','So I have been porting for a little over a month now, and I have indeed learned a lot about the porting process.  The intended goal at the beginning of the project was to convert a single codebase to support Python versions 2.5, 2.6, 2.7, and 3.2 simultaneously.  This has proven to be possible, but I am beginning to think that it is not the most efficient/proper way of accomplishing the overall goal of obtaining Python 3 support, as I continue to run into issues that require ugly hacks to solve.  I feel as though I am decreasing the overall quality of the code by attempting to satisfy both versions, and by trying to write code for both versions, I am in effect writing code for neither.  I have voiced my concerns to the GSOC mentors, and have been asked to write-up a blog post in order to compare my current porting methodology to another course of action that I am considering taking.\r\n\r\nThe Experiment\r\n--------------\r\nIn this experiment, I will be comparing two porting methods, in an attempt to gain a better understanding of the strengths and weaknesses of each method.  The first is my current method, which involves running twelve/fixing exceptions to get the tests running in Py3, then working backwards to gain compatibility for the other versions.  The second, is the method suggested [here](http://techspot.zzzeek.org/2011/01/24/zzzeek-s-guide-to-python-3-porting/), which involves using 2to3 at install in order to convert the code to Py3 code and a preprocessor that tells 2to3 to ignore certain blocks of code.  I will be using WebOb.multidict for my control code, which should provide a non-trivial and decent sized code base to compare the two strategies.  WebOb.multidict is also ideal, b/c it falls victim to most of the incompatibility issues between Python 2 and 3.  I have setup two repositories with an identical copy of WebOb.multidict on github([Method #1](https://github.com/jayd3e/WebOb-CaseStudy-Method1) and [Method #2](https://github.com/jayd3e/WebOb-CaseStudy-Method2)), and I will be going through the porting process differently on each.  I have chosen to omit version 2.5 for the purposes of this experiment, and I would also suggest removing 2.5 support from the requirements of this project.  I would like to quickly talk about why this version causes problems for the porting effort, and why I feel as though keeping 2.5 support wouldn\'t provide any major benefit.  Keep in mind that the argument against 2.5 only applies if we choose to continue to port to a single codebase.  If we end up using 2to3(method #2), then it wouldn\'t really be a problem to continue to support it.\r\n\r\nArgument Against Keeping 2.5 Support\r\n---------------------------------\r\nI strongly suggest that we drop 2.5 support if we choose not to go the \"2to3 at install\" route.  There was some talk about keeping it, due to the fact that Jython and GAE still use 2.5, but it has recently been announced that 2.5 support will be dropped by the PSF at the end of the year, which makes me question how important is to keep it around.  Someone mentioned in irc the other day that it doesn\'t seem to be very benificial to support a version that the PSF won\'t even be supporting in a few months, and I couldn\'t agree more.\r\n\r\nPython 2.6 and 2.7 already have a fair amount of incompatibilities with Python 3.  If you then add 2.5 to that list, you see the number of incompatibilties rise significantly.  Don\'t get me wrong, there are definitely ways out there to get around these incompatibilities, but in my opinion, this comes at great cost to the readability of the code.  Here are a few additional complications that 2.5 brings to the table:\r\n\r\n1. Byte literals and bytearrays are not supported.\r\n2. The new \"except Exception as e\" syntax is not supported\r\n3. Print functions and unicode literals cannot be imported from __future__.\r\n\r\nMethod #1\r\n---------\r\nFor my first method, I used my current process, which involves using twelve and six in order to get cross compatibility on both versions simultaneously.  This is the process that I used to convert this repo:\r\n\r\n1. Get 100% test coverage(WebOb already had 100% test coverage before I started porting, so I didn\'t have to satisfy this requirement).\r\n2. Use Twelve to get all of the monotonous/repetitive changes out of the way.\r\n3. Fix each exception, one by one, until all of the tests pass for Python 3.\r\n4. Then go back one version at a time to get tests passing in Python 2.7, 2.6, and 2.5.\r\n\r\nMethod #2\r\n---------\r\nFor my second method, I used the process described by Mike Bayer, which was used to port SQLAlchemy and Mako.  This method involves using the -3 python flag, 2to3 conversion tool at install, and a few special modifications to 2to3.  The process I used to convert this repo is outlined below:\r\n\r\n1. Get 100% test coverage.\r\n2. Clone two copies of the code base.  One to record all of the successful alterations, and the other to experiment with and run 2to3 on multiple times.\r\n3. Use the -3 option while running the test suite in 2.7 to see what possible warning messages I would get.\r\n4. Run the 2to3 on the experimental code base.\r\n5. Work through the exceptions one by one in the experimental code base.  All successful changes should be recorded in the main code base..\r\n6. Add the preprocessor to comment out code blocks that should be ignored by 2to3, and also add the use_2to3 flag in setup.py, so that Distribute knows to convert the code on install.\r\n\r\nConclusion\r\n----------\r\nSo after going through both processes I learned some interesting things about each methodology.  While using method #1, I found that the testing cycle ran a lot smoother.  I was able to simply make changes, then test, and repeat.  While with method #2, things seemed a little more difficult.  The fact that I had two cloned repos, meant that I had to make changes in two places each time I found something that worked successfully.  There was also the added step of undoing the changes 2to3 made, which proved to not be trivial.  Overall, I couldn\'t see an easy way to move back and forth between Python 2 and 3 code, which was kind of important considering I need to see how the code ran before and after the script.  Neither method really stood out has having vastly less exceptions from the start.  Twelve does a fairly nice job of finding all of the really repetitive changes and 2to3 does the same.  After I fixed the three or four errors in the tests and ran twelve/2to3, there were about 10 exceptions left in the code base for each method, out of 113 tests.  I would have to say that this was by far the most surprising aspect of the experiment.  I assumed that the 2to3 method at install would be far easier, but from my experience it didn\'t provide any obvious benefits.  In the end, I had to solve the same string/bytes issues, and separate the code paths in a number of identical places.  This seems pretty logical, b/c six does a number of the things almost identically to 2to3 if you think about it, but instead of actually replacing code at install, it simply chooses the correct type during runtime.  I do like how method #2 makes sure that your code is actually built for a single version at a time, but I feel as though you still need to create separate code paths for the two versions often enough, that it really doesn\'t make the code look all that different.  Have a look for yourself, and see if you see a major difference between the readability of the two repos.  I don\'t really see any appreciable benefits to switch over to method #2.  The only thing that really makes me wonder if it would be a good idea, is the shear number of large libraries who have successfully used this method.  I hope the Pylons Project and WebOb communities can further aid me in making a decision.\r\n\r\nOn a final note, there is a good chance that one or both of the repos are not fully ported.  They both pass all of the tests, but I\'m sure I missed some semantic errors here or there.  I simply ran out of time towards the end.','2011-06-28','2011-06-28 03:49:18','2011-06-28 08:56:28'),(18,'WebOb Development Sprint This Weekend','The last week or so has been incredibly slow as far as GSOC work goes to be honest.  A mixture of me being sick and my recent vacation to Texas has resulted in not a whole lot to get accomplished.  I still plan on completely porting WebOb by July 11th, which happens to be the first GSOC evaluation date.  This is only four days from now, so in order to accomplish my goal, I plan on starting a full out development sprint after work tomorrow.  This will continue through Friday night and into Saturday and Sunday.  I will be on IRC for the course of this sprint, to ask questions and gain guidance in my porting.  \r\n\r\nOn a side note, after my recent blog post, we decided that the best way to port WebOb would be to make it cross-compatible with 2.6, 2.7, and 3.2, and then use a custom set of 2to3 fixers to gain 2.5 compatibility.  So this is how I intend to continue with WebOb this weekend during the sprint.\r\n\r\nUPDATE 6/9/11:  I have started over on a new repo to simiplify the merge with v1.1.  My new repo is located [here](https://bitbucket.org/jayd3e/webob-1.1-py3), if you would like to watch my progress throughout the weekend.','2011-07-07','2011-07-07 18:35:03','2011-07-09 13:49:32'),(19,'A Retrospect Of My GSOC Experience','So as most of you may or may not know, this last Monday was the start of GSOC\'s first evaluation period.  In light of this, I wanted to write a blog post that summarizes my work done for GSOC over the last month and a half or so.  I also wanted to update everyone on the progress made last weekend during the development sprint.  So I guess I\'ll cut to chase.\r\n\r\n###Beginnings\r\nBack towards the end of May, when GSOC first kicked off, I was given two packages to port to Python 3 for this first evaluation period.  The requirement was that I get TranslationString and WebOb running under 2.5, 2.6, 2.7, and 3.2, and since both packages had 100% test coverage from when I got my hands on them, completing the port equates to getting all of the tests passing in each version.  So after I fully understood the goal, I quickly begun the process of educating myself in porting.  The first thing I did was read as many articles as I could find on the subject.  Surprisingly, there were very few at the time, besides the obvious ones on the main Python website.  A few really good ones of spawned in the time since.  I also read Lennart Regebro\'s book \"Porting to Python 3,\" which proved to be an excellent read, and gave me most of the knowledge I would need to get started.  I wrote a pretty extensive blog post on the contents of this book earlier. I pretty much dedicated the entire first week to just educating myself.  After the learning period was over, I dove right into porting TranslationString(the smaller of the two packages).\r\n\r\n###TranslationString\r\nTranslationString was not very big at all, but it was definitely not trivial(well kind of heh).  It consisted of a single file, and two test files.  I knew from the beginning that I wanted to automate this process as much as possible, so I created a custom set of fixers for 2to3 that I called Twelve.  This set of fixers includes some automated conversion of Py2 types to Six types and it also fixes some incompatible Python 2 syntax(such as the old \'except\'/\'raise\' syntax).  In order to port TranslationString I simply fixed all of the syntax errors that occurred in the tests and then went through the 20-30 exceptions thrown upon running the tests in Python 3.  As I did this, I tried to make custom fixers for as many of the exceptions as possible, to avoid having to do them in the future.  This porting process ended out working pretty well, but I think that was partly due to the size of the package.  After about a week I issued a pull request on [my fork](https://github.com/jayd3e/translationstring) of the repo.  I was notified shortly after that I had a few monkey patching issues(I was new to the concept of monkey patching at the time).  I fixed these issues, updated the pull request with my new commit range, and my changes were merged with the standard repo.\r\n\r\n###WebOb\r\nSo as I waited for TranslationString to get properly pulled, I took the liberty of starting on WebOb.  For my first attempt at WebOb, I tried using the same porting process that I had with TranslationString.  I would use this process for the next three weeks or so.  This proved to be somewhat problematic.  WebOb is a great deal bigger than TranslationString.  It\'s composed of 14 modules and around 800 tests.  It was easy to get all of the tests actually running, but once I did, I was overwhelmed by around 200-250 exceptions being thrown upon running the tests in Python 3.  Not only was this overwhelming to look at, but I also wasn\'t really able to see patterns of incompatibilities in the code.  I also really didn\'t get a chance to understand what the code was doing, because I wasn\'t really looking at a specific module at a time, I would be forced to hop around from module to module at the whim of the exception list.  So after about two-three weeks of doing this, I began to doubt my methods, b/c I seemed to not be making as much progress as I had hoped.  I spent a little time in #python, and I was quickly informed that most of the Python community believes that trying to support Python 2 and 3 on a single code base without the use of 2to3/3to2 is far too difficult to be realistic.  A number of individuals also mentioned that it makes your code unreadable and sloppy.  The widespread disapproval of the way I was doing things at the time was enough incentive for me to do some further investigation.\r\n\r\nAfter my little discussion with the folks of #python, I talked it over with some of the Pylons Project leaders and everyone thought it would be a good idea to do a quick experiment that involved using multiple porting methodologies to port a common piece of code and comparing them in the process.  I would say the most important lesson that I took away from the aforementioned [experiment](http://jayd3e.com/post/view/17) were that although there were some definite differences between the two strategies, they were mostly the same in a lot of respects.  The code had to be forked in a lot of the same locations and certain syntax had to be corrected in both methods, as some syntax had neither 2to3 or six support.  It really came down to whether you wanted to do most of the type conversion during run-time(thus negatively affecting the speed of the code at run-time) or during install/testing(which makes the development/install process slower).  Either way your going to incur a speed deficit.  Others may have a good argument against this comparison of methodologies, but that is at least the conclusion I came to.  I also found that 2.5 really creates a number of inconveniences when attempting to gain cross-compatibility between 2 and 3, which is largely why I encouraged dropping support for 2.5 in my analysis.  In the end the conclusion that we came to for WebOb, was that I would port the package to be compatible for 2.6-3.2 on a single code-base, and then we would use 2to3 fixers to gain 2.5 support.\r\n\r\nSo after it was clearly decided what my new goal would be, I started a [new repo](https://bitbucket.org/jayd3e/webob-1.1-py3), pulled over all of my meaningful changes from the [old repo](https://bitbucket.org/jayd3e/webob-py3), and began porting WebOb again, with a number of improvements.  I got into contact with Sergey(WebOb\'s maintainer), who has been an enormous help over the past week or so.  I planned on having WebOb ported by the 11th, but I unfortunately was not able to meet that goal.  My recent development sprint helped me get caught up after my recent vacation, but it did not result in the completion of WebOb as I had hoped.  Sergey and I definitely got through a number of problems, and he was able to fill me in on some general WebOb knowledge, as well as some of the problems he is expecting we will need to face in the near future.  So that leaves us at the present.  I am simply going to keep working on WebOb until it is complete.  As previously mentioned, it is a pretty large package, so I am not completely surprised it is taking this long.\r\n\r\n###Conclusion and Thanks\r\nIn the end, I am really happy with my experience so far.  I have learned a ton, and I hope the second half of GSOC will be just as meaningful.  I would like to thank anyone who has ever answered any of my countless questions in the mailing list and IRC, everyone has been a great help, especially the GSOC mentors.','2011-07-14','2011-07-14 01:01:25','2011-07-14 01:02:54'),(20,'GSOC - 2nd Half Goals ','So I am pretty pleased with the way the first half of GSOC went, I learned quite a bit, and as always got my hands dirty with a lot of Python code.  I would like to make this second half even better by doing a little planning and goal-setting.  In hindsight, there were three main problems with my porting methodology that I want to get right this second time around.  \r\n\r\nThe first was that I don\'t believe I contacted the WebOb community early enough.  They are obviously far more knowledgeable about WebOb then I, so it makes sense that they are the \"go to\" people to seek guidance about WebOb related topics.  I have corrected this over the last two weeks, as I have been discussing porting efforts with Sergey(WebOb\'s maintainer) quite a bit.  I plan on continuing to keep in close contact with the WebOb community throughout the remainder of GSOC.\r\n\r\nSecondly, I don\'t believe I kept a steady, realistic schedule.  This resulted in me doing the majority of my work in 3-4 large chunk of ridiculous amounts of time(which is often how I program anyway).  This proved to be inefficient and monotonous at times.  It also made it difficult to get the proper guidance at times, as everyone else\'s schedule usually did not overlap with mine.  To correct this, I have instituted a \"work-time\" so to speak.  I will be working every weekday night from 8-12 CST and sporadically throughout the weekend.  This will add up to a minimum of 20 hours a week, and on most occasions between 20-30, which I think is a reasonable enough amount of time to accomplish our goals with my current porting knowledge.\r\n\r\nThe last and final thing that I will be correcting this time around, deals with modularizing my efforts.  During the first half, I would commonly port things all at once, by simply going down the exception list.  Looking back on it, this was obviously a terrible idea.  I plan on only focusing on a single module at a time, starting with the smallest.  This will make it far easier to understand the code I\'m porting, and hopefully increase the quality of my work.  I started with datetime_utils(the smallest module), and have now moved on to multidict, as the headers module(second smallest) depends on it.\r\n\r\nThat\'s all folks.','2011-07-21','2011-07-21 23:01:04','2011-07-21 23:01:04'),(21,'And Another Two Bite the Dust......','So this entry is a little late, but I have a lot of good news to report.  Last week was an incredibly successful one, and I hope to make this week just as eventful.  Monday and Tuesday did not yield many results, but I took off work on Wednesday to do GSOC stuff, and bulldozed through 2 modules and half of another.  So as I may have mentioned in my previous entry, I ran into problems with the headers.py module, because it had a number of dependencies in multidict.py.  So I simply moved on to multidict.py, got all of the tests running on it, and then did the same for headers.py.  I also got about half way into cookies.py, and ran into some errors.  Specifically, I wasn\'t sure about the proper encoding for the first argument of the _needs_quoting() function.  I later talked to Sergey about this, and he mentioned that the first argument will be exclusively \"bytes\", and it is not a part of the public API, so I don\'t need to worry about a \"str\" accidently getting passed into it in Python 3.  I think most of the issues in cookies.py are due to the tests being incorrect.  It is not an incredibly long module, so I should be able to inspect it further and using the information that Sergey provided me, determine which tests are correct/incorrect.  I plan on completing cookies.py tomorrow.  I think taking one module at a time is really making it lot easier to port WebOb, because I am able to actually learn the code as I go along.  It also does wonders for my moral, as I am less likely to become overwhelmed by a given task.','2011-08-01','2011-08-01 00:44:17','2011-08-01 00:44:17'),(22,'Better late than never!','So I haven\'t blogged in a while.  Ok that is a bit of an understatement, I haven\'t blogged since the beginning of the month :(.  This absence from the blogging sphere has not been unwarranted as I have had a few rather large family matters come up, but it is still no excuse and I apologize.  My effort on the project has not faltered in this absence, however, and I have made a number of really huge strides, especially in the last week.  I have continued to follow the \"module by module\" approach on webob and have gotten a number of modules to pass 100% of tests between the two versions.  Here is the definitive list of each WebOb module along with its respective status:\r\n\r\n* acceptparse.py - 12 errors and 1 failure\r\n* byterange.py - passes all tests in 2.7 and 3.2\r\n* cachecontrol.py - passes all tests in 2.7 and 3.2\r\n* cookies.py - passes all tests in 2.7 and 3.2\r\n* datetime_utils.py - 0 errors and 2 failures\r\n* dec.py - Uses Request, so Request will have to be ported first before I can get to this.\r\n* descriptors.py - Ported until I discovered that Request would also have to be ported in order to pass all tests.\r\n* etag.py - passes all tests in 2.7 and 3.2\r\n* exc.py - Uses Response, so Response will have to be ported first before I can get to this.\r\n* headers.py - passes all tests in 2.7 and 3.2\r\n* multidict.py - passes all tests in 2.7 and 3.2\r\n* request.py - 0 errors and 29 failures(went through and fixed the 130 or so errors first)\r\n* response.py - haven\'t gotten to it\r\n* util.py - passes all tests in 2.7 and 3.2\r\n\r\nOn another node, Alex Gronholm is porting a parallel repo.  So once we are both done porting WebOb, we will compare our work and determine which parts we will keep from both repos.  So WebOb should be ported very soon I would hope, for everyone wondering when it is actually going to happen.  So that should give everyone a fairly decent status update on Webob.  Now onto a more subjective topic.\r\n\r\nA Retrospect on GSOC\r\n--------------------\r\nSo I wanted to give a short retrospect of the second part of my GSOC experience, by using the final evaluation form as a guide. \r\n \r\n###Considering your original project plan, how close would you say you are to having met all the goals you originally outlined?\r\nI would say that I got decently close to finishing the project goal(completely porting WebOb and TranslationString).  I finished TranslationString and am through most of WebOb.  Granted due to the size of WebOb, tests will have to be reviewed and the new ported version will have to go through some rigorous testing within real software, but the initial port is nearing completion.\r\n\r\n###Have your communications with your mentor and/or organization changed since the midterm evaluations?\r\nNot a whole lot.  I don\'t feel like communicating with my mentors/organization was ever really a problem from the start.  I was always able to get help whenever I needed it via IRC.  I am most pleased by this aspect of the program.\r\n\r\n###How would you rate your experience with the program overall?\r\nI really enjoyed GSOC, and will definitely do it again next year, and advise other students to do the same.\r\n\r\n###How much time have you spent working on your project since the midterm evaluations?\r\nI would say at the very least I would spend 20 hours a week on the project and usually an average of 30 hours a week.\r\n\r\n###Since the midterm evaluation, how would you describe the amount of time you\'ve spent on the project?\r\nI\'ve spent about the same amount of time since the midterm evaluation, possibly a little less, but I usedmy time far more efficiently in this second half and accomplished a lot more.  I felt like I actually knew what I was doing this time around.\r\n\r\n###What has been the most challenging and/or rewarding part of participating in Google Summer of Code?\r\nI would say the most challenging/rewarding part of GSOC was reading another person\'s code and learning the code base.  Ian is an incredibly good programmer and he uses every corner of the stdlib, so at times his code was very confusing and hard to navigate.  This really stengthened my ability to read Python code, a very valuable skill to have.  \r\n\r\n###What one thing could your mentor or mentoring organization do differently or better for future students in future years?\r\nI felt like I was given a great deal of freedom from my organization, but at times it felt like it was almost too much freedom.  I would have appreciated just a little more structure and guidance as to how to go about my project. I also understand that I was kind of experiencing some uncharted territory, so it may have been hard for them to give me any concrete advice.\r\n\r\n###What one thing that your mentor or mentoring organization did do you consider very helpful for your project and would suggest they continue to do?\r\nThey were always available.  Someone was always on IRC to answer my many questions.  Keep doing that lol.\r\n\r\n###What advice would you give to students participating in Google Summer of Code in the future?\r\nI would just advise to stay very connected with your mentors, and make sure that you give them frequent status updates/blog entries.  I was not always the best at this, but I hope I did a sufficient enough job to give them a ballpark of how I was doing.\r\n\r\nSo that\'s it.  My last GSOC blog.  Thanks for everyone who helped me along the way, had a blast.  On an ending note, I\'m not going anywhere.  After WebOb, comes WebTest.  Then another module and so on, until Pyramid gets ported.  I\'ll be in #pyramid, peace.','2011-08-25','2011-08-25 00:54:27','2011-08-25 00:56:30'),(23,'Keeping playdota.com Honest','So recently I have been pretty obsessively pursuing a Dota 2 beta key in any means available, and after two weeks I still don\'t have one.  Anyway, this journey to obtain a key, like a number of other people, took me to the playdota.com forums.  I specifically frequented the Beta Key Chat section of the site, a temporary forum that has been set up for the specific purpose of raffling/selling/trading beta keys.  The site itself actually has a large raffle constantly going on.  It works like this, a member of the forum goes to a specific thread and posts a message.  By posting in the thread, you are automatically entered into the contest, and a bot that is run everyday around 10am will pick a certain number of members to give beta keys to.  This number started at only 2-3 members and has now steadily increased to 40.  This means 40 members out of about 62,000(accurate at the time this was written) repliers are given beta keys everyday.  Once the members are chosen, they are automatically outputted in another separate thread, that prints them in a very predictable format.\r\n\r\nSo everything was going all well and good with this system until recently, when a user named nonstopaz posted a supposed \"Shocking Discovery\" about the beta key draw [here](http://www.playdota.com/forums/573291/shocking-discovery-pd-beta-key-draw/).  He claimed that the algorithm used to pick the 40 random members was in no way random, and that all of the new users that had simply joined the forum to join the contest were getting cheated, as the algorithm was biased to OLDER members with over 300 posts.  he further claimed that the distribution of the keys went something like this:\r\n\r\n* 15 keys to OLD members with 300+ posts\r\n* 15-20 to OLD members with 20+ posts\r\n* 5 to RANDOM people\r\n\r\nThis means that according to beta key draw algorithm, about 37.5% of the picks were being allocated for OLD members with 300+ posts, 50% for OLD members with between 20-300 posts, and a measly 12.5%  for purely random users.  Naturally a number of people were kind of shocked by this, because the mods of playdota.com had said that the contest was completely random, and mentioned nothing about a bias towards specific members of the site.  I mean I don\'t blame them for wanting to reward their most loyal members, but it just seemed kind of dishonest for them to modify the contest in a way that had never been previously mentioned.  Some members were not so convinced by nonstopaz, and were quick to say that this accusation was not based on fact.  So I decided to keep everyone honest, and see exactly which kinds of members were getting the keys.\r\n\r\nSo I knew where all of the users were getting displayed, and I knew how to access their profiles, so I saw no reason why this process could not be automated.   So I first wrote a quick script that used tornado.httpclient to fetch each page of the the winners thread, compile a giant list of all of the members, and then used httpclient again to visit each of the users profiles and parse out their total posts and join date with lxml.  At this point I have a giant dictionary of about 741 members, with each member\'s respective total posts and join date.  After I had this information, the sky was the limit, I could find averages, percentages of certain groups, and even find patterns in the data, to find if nonstopaz\'s claim was actually legitimate.  I wanted to share this data with everyone else, so I did it in the best way I know how.  I used my favorite web application framework, Pyramid, and whipped up a site that generates the member list once each day and caches the result using dogpile.  You can find the current live version of the site [here](betashocker.jayd3e.com).\r\n\r\n###Problems I Encountered\r\nIt sounds pretty trivial to get a bunch of names from a list, get some info from their profiles, and message it; however, there are some small things that gave me a lot of trouble.  The biggest being character encoding.  You guys have some pretty funky names, with a bunch of weird symbols specific to certain encodings.  It didn\'t take long for me to realize that out of the 741 page visits it would take to get everyone\'s profile, a number were failing b/c I wasn\'t crafting the url correctly.  What I ended up having to do, is decode the responses from the winners thread into unicode using the windows-1250(why playdota.com!?!?) codec(determined that by using [this](http://www.motobit.com/util/url-encoder.asp)).  Once I had the names in unicode, it was easy relatively easy to get them into everything else.  One problem that took me a bit to figure out was that lxml was changing certain chunks of the responses into unicode and guessing(ugh...) the character encoding incorrectly.  So what I ended up having to do was change the response to unicode before I passed it into be parsed by lxml, as outlined [here](http://www.netsight.co.uk/blog/unicode-stuff-and-lxml).  This allowed me to more easily get everyone\'s name in unicode from the start.  Even after all of this, I still had problems with a few names that were for some reason not encoded with windows-1250, so I simply excluded those names from the data set.  I also had some problems with spaces in usernames and commas in total posts, but those were relatively easy to fix.\r\n\r\nAnother problem I encountered, was a number of requests would often just time out, for apparently no reason.  To combat this, I simple made a get_page() function that would attempt to get the page multiple times, with an increasingly longer sleep between the attempts.  This almost ensures that the page will be returned, so the script can continue.\r\n\r\nThe last problem I encountered is a common one, the thundering herd.  Wikipedia defines this problem as when a large number of processes waiting for an event are awoken when that event occurs, but only one process is able to proceed at a time.  I would soon have a number of members attempting to view my site, and obviously I couldn\'t go through a process that takes about 30 minutes to fully complete each time a visitor wants to view my page.  It was also completely unnecessary to have my data accurate to the minute, when it only changes on a daily basis.  So I opted to just form the member list once every day and cache the result.\r\n\r\n###Source Codez\r\nI have made the site/method completely public.  You can find it at [github](https://github.com/jayd3e/BetaShocker).','2011-11-22','2011-11-22 20:36:24','2011-11-22 22:39:00'),(24,'Betashocked Round 2','So in my last post, I wrote about how I had wrote some code that parses the beta key draw thread at playdota.com, in order to look further into whether or not the raffle is actually using an algorithm that has a tendency to pick older members with more posts over younger members.  As I mentioned this was very successful, and I was able to obtain some information about which percentage of the winners fit into the following three groups:  members that are over a year old and have 300+ posts, over a year old and have between 20-300 posts, and members that are younger than a year old with less than 20 posts.  The distribution was about 35%, 42%, and 27% respectively.  I also found that, on average, winners had 300+ posts and around 600 days of membership.  This was all well and good, but I quickly realized that all of this information was meaningless, unless I knew what percentage each of those three groups occupied in the full entrant data set.  Because for all I know the full entrant list could have contained the same percentages of each of the three groups, thus making it quite possible that the contest could be completely random.  I would never really know unless I parsed the 3,250 page thread that contains all of the members who have entered the contest...so this is precisely what I did.\r\n\r\nSo after doing some quick code refactoring to separate different functionality into individual modules, I began essentially replicating what I had done for the member list for the entrant thread, with a few modifications.  Unlike the winners list, the entrant thread already contained the total posts and join date specific to each member, so I would not have to go to everyone\'s profile page this time.  Good thing to, b/c that would have been virtually impossible, and would have been process that would have exceeded my patience most likely, I mean as if waiting for 3,250 pages to get parsed was not enough.   So I eventually got to a point, where I was successfully parsing the whole list, and then memcached threw a curve ball at me.  I guess there is a 1mb limit on values stored in memcached, and the final dictionary that contained each member\'s name mapped to their specific total posts/join date was definitely over that limit.  This limit is in place for good reason, b/c for one, anymore than a megabyte is going to take too long to load for any reasonably large site on a regular basis and also due to the way memcached stores data in \"slabs,\" its efficiency of the storing process decreases the larger the value is.  This kind of left me stuck, however, because I really couldn\'t store the dictionary in pieces and only dealing with a partial entrant list was worthless to me, I needed the whole thing in order to find the true metrics.  As I was riding in the car on the way to my grandma\'s house for thanksgiving dinner, it suddenly struck me that I didn\'t need to store the member data all in one place, I could spread it out.  I resolved that I would instead store a list of the entrant names as one key/value pair, and then I would store each member\'s data as an individual key/value pair.  This way, each time I needed the full data set, I would loop through the entrant\'s list and retrieve each member\'s data out of memcached using the names in that list.  It also suddenly came to my attention, that all of the members in the winners list would already be in memcached by the time that I needed them, so it would no longer be necessary to go to each winner\'s profile to parse out the relevant information, so I just wiped out all of the code that was dedicated to doing that.  I would also no longer need to generate any urls(I was generating the urls to each profile page myself), so I also wiped out all of the code that dealt with getting each name into the proper character encoding, as I didn\'t really care if the names were correct, they just needed to be unique to provide a unique key.  The last little hurdle I had to solve, was memcached started complaining about some of the keys(member names) having spaces, so I had to just had a few lines that checked/handled that specific case.  This left me in a pretty good spot.\r\n\r\nSo after I implemented this new system, things seemed to get dramatically easier.  This is the process the site goes through once daily to find pertinent data:\r\n1. Go to each page in the PlayDota Beta Key Draw thread, and parse out each entrant as well as their join date/total posts.\r\n2. Store a list of all of the entrants in memcached in this format -> \'winners\' : [\'list\', \'of\', \'members\'], and store each member in this format -> \'member_name\' : {\'total_posts\' : 5, \'join_date\' : datetime.date}.\r\n3. Go to each page in the Daily Draw Winners thread, and parse out each winner.\r\n4. Build a full dictionary of each entrant mapped to their total posts/join date, and generate some statistics.\r\n5. Build a full dictionary of each winner mapped to their total posts/join date, and generate some statistics.\r\n\r\n###Conclusion\r\nSo most of you are probably wondering, so is the key draw weighted?  The answer is yes, very much so in fact.  Just as I suspected, there is a huge percentage of people in the entrant pool with less than 20 posts and less than a year of membership.  The nice folks at playdota.com must have noticed this early on, and decided that it was unfair to their senior members.  To reiterate, the three groups of members are:  members that are over a year old and have 300+ posts, over a year old and have between 20-300 posts, and members that are younger than a year old with less than 20 posts.  If the raffle was completely random, we would expect that the percentages of each group in the winner\'s pool would be very close to the percentages occupied by each group in the entrant pool.  This is not so, the distribution in the entrant\'s group comes out to be around 80%, 18%, and 1% respectively.  So not even close really, which means that the bot is not picking at random.\r\n\r\n###Final Notes\r\nSo that is it.  I think I\'m going to be done with this project, as I would like to get to other things, but it has been a very fun little tangent to mess around with during thanksgiving break.  Once again, the new version of the site can be viewed [here](betashocker.jayd3e.com).','2011-11-25','2011-11-25 01:30:20','2011-11-25 01:44:05'),(25,'Upboat This Post','So I am huge redditor.  I use reddit as a news source, for entertainment, as a gaming community, and the list goes on.  One of the biggest reddit claims to fame is their social voting system and the algorithms they use to sort their content.  On reddit, you can pretty much vote on everything, and the site is able to very cleverly use all of this data to sort the content and decide upon which posts/comments/replies are going to be more relevant to the user, thus improving their overall experience with the web app.  On a recent site that I made for the Reprap community(still undeployed and in a certain state of \"site limbo\"), I implemented a very primitive version of a reddit-like social voting system.  I decided that I wanted to pull this functionality out, and create a demo/tutorial to demonstrate how I accomplished this.  So the following is the aforementioned tutorial, which I plan on putting in the Pyramid cookbook once it is completed.  \r\n\r\nThis tutorial will take you through all of the steps of creating a very simple reddit-like application using Pyramid.  I assume that you have absolutely no experience with Pyramid, but at the same time builds a very usable real-world application and uses a number of conventions created by the Pyramid community, so noobs and advanced users are both welcome.  I also ask that you actually type out all of the code samples given(even the comments, as a lot of information is hidden them), so that way by the end of the guide, you have a full working application.  For the lazy, all of the source code will be located [here](#).  This tutorial is organized as follows:\r\n\r\n1. Setting Up Your Environment\r\n2. Writing the Base Site\r\n3. Upboat All the Things\r\n\r\n###Setting Up Your Environment\r\nMost tutorials will use a scaffold to get something to display in a browser quickly and easily; however, I have chosen to just show you how to write all of the base files, as I like the idea that after you\'re done with this tutorial, you will know what each line of your application does(which is a very comfortable feeling).  So first things first, let\'s talk about directory/file structure.  As we go along, I am going to show you what the file structure should look like at every stage of the process.  So that way you can follow along and go through each step in creating your app.  First things first, let\'s setup your project directory and virtualenv.  Your file structure will look like this after your done:\r\n\r\n    Upboat/\r\n    |-- env\r\n\r\nMake a directory entitled \'Upboat\' and cd into it.  The next stage will use virtualenv to create a virtual python environment, that will allow you to keep your package management for this application separate from the rest of your system.  I always like to install virtualenv on the system python.  Use the following command:\r\n\r\n    jayd3e ~/Projects/Upboat $ easy_install virtualenv\r\n\r\nNow that we have virtualenv, we need to compile the version of python we want to use.  Pyramid is compatible with 2.5, 2.6, and 2.7, but I personally like to always use 2.7.  In order to download and install 2.7, in a directory other than your project directory, use the following commands:\r\n\r\n    jayd3e ~/opt $ wget http://www.python.org/ftp/python/2.7/Python-2.7.tgz\r\n    jayd3e ~/opt $ tar xvzf Python-2.7.tgz\r\n    jayd3e ~/opt $ cd Python-2.7\r\n    jayd3e ~/opt $ ./configure\r\n    jayd3e ~/opt $ make; make install\r\n\r\nOk great now we have a python to use within our virtualenv.  Finally to create the virtualenv, use the following command from with the root directory of your project:\r\n\r\n    jayd3e ~/Projects/Upboat $ virtualenv --no-site-packages --python=/path/to/Python-2.7/bin/python env\r\n\r\nThis tells virtualenv to create an environment in a folder called \'env\' in the current directory, which uses the python that we compiled, but doesn\'t include any of the packages already installed in that python.  So now the directory structure should look familiar, a root project directory with an virtualenv inside of it.  Now let\'s activate this virtualenv by typing these commands:\r\n\r\n    jayd3e ~/Projects/Upboat $ cd env/bin\r\n    jayd3e ~/Projects/Upboat/env/bin $ . activate\r\n\r\nOn most systems, a period is an alias for \'source\'.  Your prompt should now look something like this:\r\n\r\n    (env) jayd3e ~/Projects/Upboat/env/bin $\r\n\r\nThis means that virtualenv has altered the system path in such a way, that if you now call \'python\' you will be calling the python within your virtualenv, this goes the same for a variety of other executables, like \'easy_install\' and \'pip\'.  You should have this virtualenv activated while doing the rest of the steps in this guide.  So now let\'s add some more files into the mix.\r\n    \r\n    Upboat/\r\n    |-- env\r\n    |-- upboat\r\n    |    |-- __init__.py\r\n    |-- README\r\n    |-- CHANGES\r\n    `-- setup.py\r\n\r\nEasy enough.  This is where any new application should begin, with a standard setuptools package.  The README file, by convention, contains a description(detailed or not) of what the package does, and may also include instructions on how to install/use the package.  It is helpful to know that both [github](github.com) and [bitbucket](bitbucket.com) use the README file in the root of a repository in order to display a description of the repo.  This is what your README file should look like:\r\n\r\n    # Upboat/README\r\n    A simple reddit-like application that allows people to post links, and vote on them.\r\n\r\nThe CHANGES file contains a list of changes made between versions, and is usually the main source for your software\'s patch notes.  We haven\'t written anything yet, so we don\'t really have anything to include in this file quite yet.  The \'upboat\' folder is the folder that is actually representative of your module.  By convention it is usually your project name, in our case \'Upboat\', written in all lowercase.  It is also important to note, that the __init__.py file is what actually makes it a python module and accessible through \'import upboat.\'  We will also be putting all of our configuration for data Pyramid in the __init__.py file.  Lastly, the setup.py file contains specific information about your application that will assist setuptools in installing the correct dependencies for your package and also in distributing your application.  Let\'s make it look something like this:\r\n\r\n    # Upboat/setup.py\r\n    import os\r\n    from setuptools import setup\r\n    \r\n    # locates the README and CHANGES file, and reads their contents into strings\r\n    here = os.path.abspath(os.path.dirname(__file__))\r\n    README = open(os.path.join(here, \'README\')).read()\r\n    CHANGES = open(os.path.join(here, \'CHANGES\')).read()\r\n    \r\n    # specifies the entry points of our application\r\n    entry_points = \"\"\"\r\n          [paste.app_factory]\r\n          main = upboat:main\r\n          \"\"\"\r\n     \r\n    # specifies a list of required packages for your application\r\n    requires = [\'pyramid\',\r\n                      \'sqlalchemy\',\r\n                      \'mako\']\r\n    \r\n    # the main function call to setuptools to define your package\r\n    setup(name=\'Upboat\',\r\n              version=\'0.1dev\',\r\n              description=\'\',\r\n              long_description=README + \'\\n\\n\' + CHANGES,\r\n              install_requires=requires,\r\n              url=\'http://localhost\',\r\n              packages=[\'upboat\'],\r\n              test_suite=\'upboat.tests\',\r\n              entry_points = entry_points\r\n    )\r\n\r\nWhile your looking at setup.py, I would like to briefly talk about entry points.  Entry points are pretty awesome and have a variety of different applications.  The beauty of entry points is that they basically make other applications, that have no knowledge of your application, aware that you exist.  Let me give you an example that directly relates to Pyramid.  So I\'m sure by now you have scoured Pyramid\'s docs, and you know what a Pyramid scaffold is.  If you don\'t, a scaffold is essentially just a pre-built directory structure and some basic pre-written files that you can build off of to create your own application.  Going on, you use the \'pcreate\' command to locate the scaffold and copy all of the different files and directories within it, to the directory your new project is located in.  The \'pcreate\' command doesn\'t know where all of the potential scaffolds could be, because realistically, they could be anywhere.  A user might want to create their own scaffold in fact, and put it into a custom directory.  So how exactly does pcreate find all of the available scaffold throughout the entire system you may ask?  Through entry points!  What \'pcreate\' basically does is it uses the \'pkg_resources\' module to ask the current Python for all of the packages that have registered to a specific entry point, and then uses that list of scaffolds to find the one that you specify when you use \'pcreate\'.  It basically provides a really simple way to implement plugins at the package level.  Now let\'s take a look at how your package uses entry points.  As you can see in the entry points section of your setup.py, we are registering the \'main\' function within the \'upboat\' module to the \'paste.app_factory\' entry point.  This way, later when we go to serve our application, paster will be able to find the function that returns a wsgi app.\r\n\r\nSo now we are at the point where we have set up your Python \"package\" for the application.  In fact, if you run:\r\n\r\n    jayd3e ~/opt $ make; make install\r\n\r\nYou should then be able to launch a python interpreter, and access your module by typing \'import upboat\'.  Obviously there is nothing in it, so you won\'t be able to do a whole lot, but you should still be able to access it.  Moving right along, we now want to create the actual Pyramid elements of our application, now that we have a working module of our own.  Here is what it will look like when we\'re done.\r\n\r\n    Upboat/\r\n    |-- README\r\n    |-- CHANGES\r\n    |-- development.ini\r\n    |-- production.ini\r\n    |-- upboat\r\n    |   |-- __init__.py\r\n    |   |-- static\r\n    |   |   |-- css\r\n    |   |       |-- reset.css\r\n    |   |       |-- style.css\r\n    |   |       `-- type.css\r\n    |   |   |-- img\r\n    |   |   `-- js\r\n    |   |-- templates\r\n    |   |   `-- index.mako\r\n    |   |-- views.py\r\n    |   |-- resources.py\r\n    |   `-- models.py\r\n    |-- env\r\n    `-- setup.py\r\n\r\nPyramid makes absolutely no assumptions about where each element of your code is, so it is entirely up to you on how to organize it.  This may seem daunting at first, but there is a great amount of freedom that comes with this fact and allows you to make your app as large or as small as you want.  So let\'s start creating all of these files.  The development.ini file is a file specific to Paster, which is the web server we are going to be using.  It is consumed by the \'paster serve\' command to make sense of our wsgi application.  Our development.ini is going to look like this:\r\n\r\n**Note:  I have decided that this tutorial is much too broad, and it would require me to rewrite a lot of Upboat\'s current code to act more like an actual website.  I decided that most of the topics I was talking about have already been discuss to great lengths in the docs, so not only would I be adding very little value, I would only be making the process more confusing by adding another resource.  I have decided to strictly focus on the task of implementing social voting in a site, and create a quick description of Upboat\'s source, as it would better serve the community.','2011-12-02','2011-12-02 15:56:38','2011-12-05 15:49:20'),(26,'Helping Out the Dota 2 Community','So I felt bad about using up so much of playdota.com\'s bandwidth over the course of my last shenanigans, so I decided that I would help the community out a bit, as I really love the games that this group of people play.  I recently got into the Dota 2 beta, and have been playing it pretty frequently.  I was scanning the dev forums and came across this [thread](http://dev.dota2.com/showthread.php?t=6207&page=6), where a number of people were sharing configurations for in-game hero guides.  Towards the end, a few people were talking about creating a C# GUI to make it easier to create guides and generate the respective text files.  While I was reading this, I was thinking to myself how stupid of an approach this was in this modern age.  I mean think about it, this guy is going to create a gui of some kind, and then a hundred or so people might download.  After that happens, how does he plan on adding new items/heroes as they are added into the game?  What about bug fixes, how does he plan on pushing updates?  This would be just as simple to create a web application for, and it would be a thousand times better, as I could add new items/heroes to a central database and push updates instantly.  So I have decided that I am going to create such a \"guide creator\" web application that will meet the requirements laid out in that thread.  I\'m calling it D2.  This will go along nicely with my idea to create a MOBA search engine of sorts, that will be able to provide a live search for all heroes/items/guides in the MOBA genre.  This will provide me with a solid set of user-created guides to begin the search engine later.  My plan is that I will get done with it this weekend, which is a little ambitious, but seeing as I am starting development on Project Ocelot soon, I don\'t have a lot of time.  So I really plan on pushing myself this weekend to get this done.','2011-12-02','2011-12-02 23:41:57','2011-12-02 23:43:43'),(27,'Troubles With Postgresql on Mac OSX Lion','So I just spent much too long solving a problem with Postgres on Lion. I was getting an error like this:\r\n\r\n    psql: could not connect to server: Permission denied\r\n    Is the server running locally and accepting\r\n    connections on Unix domain socket \"/var/pgsql_socket/.s.PGSQL.5432\"?\r\n\r\n The problem ended up being caused by the fact that Lion comes with a version of Postgres pre-installed so all of the major scripts like createdb, psql, and pg_ctl were all pointing to the executables in /usr/bin(where the pre-installed version was), as opposed to /usr/local/bin(where homebrew installed my postgres).  I solved this by adding this line to my ~/.profile file:\r\n\r\n    export PATH=usr/local/bin:/usr/local/sbin:$PATH\r\n\r\nAfter that all I had to do was use this command to initialize the database:\r\n\r\n    initdb /usr/local/var/postgres\r\n\r\nOne little quirk that I ran into, was this command actually starts the database daemon as well, so there is not need to run \'pg_ctl -D $DIR start\'.  You should be able to interact with the database with the current user after following the above two simple steps.','2011-12-03','2011-12-03 20:12:34','2011-12-03 20:12:34'),(28,'Upboat This Post Again','So previously, I started making a tutorial that went into great depth about the entire process of making a webapp in Pyramid and treated the social voting functionality as more of supplemental knowledge; however, in the end I decided that it would better serve the community to make a far shorter \"guide\" on how to implement social voting in a web site.  So here it is.  It should also be known that I recently made a much prettier version of this tutorial that can be found [here](http://upboat.jayd3e.com/).\r\n\r\n###Adding Social Voting to Your Pyramid App\r\nSo you\'ve been to Reddit, Digg, StackOverflow, and the billion other sites that use social voting, and you love the concept of your users rating the importance of your content completely for free.  This guide will go through the basic steps of implementing such a system, and also give you some working source code to see how I created one.  I\'m not really calling this a \"tutorial\" per se, as I am not going to really go through anything step by step.  I am mostly going to give you the higher level details.  Then using the code I have provided, and the concepts I introduce, you should be able to go out into the big wide world and write your own.  This seems fitting, as social voting is a piece of functionality that is very closely connected to your data, so having you create some dummy app with social voting might not be the best use of your time.  Due to this, I would say that this guide is probably written for moderate/advanced Pyramid/SQLAlchemy users.  So let\'s start.\r\n\r\nSo first things first, I have created a very simple social voting implementation [here](https://github.com/jayd3e/Upboat).  In order to test it out, run the follow commands:\r\n\r\n    jayd3e ~/Projects/Upboat $ python setup.py develop\r\n    jayd3e ~/Projects/Upboat $ python demos/demo.py\r\n\r\nYou should see something like this get printed out:\r\n\r\n    serving on 0.0.0.0:5020 view at http://127.0.0.1:5020\r\n\r\nYou can then view the application by going to http://127.0.0.1:5020 as it mentions.  Basically this page just demonstrates that a single user can click on the up/down vote arrows, and have those actions persisted in the database.  The demo really doesn\'t show much, as it only uses a single global user id, but if you were to actually implement this on a working site, with multiple users, each up/down vote would be linked to their respective user.  So anyway, how does it work?\r\n\r\n\r\n###Database Representation Of the Data\r\nLet\'s start with the obvious things.  In order for something to get voted on, you need the \"voted\" and the \"voter.\"    In other words, you need an object of some sort, usually a comment, post, or link, and a user to say they either like or dislike that object.  So using this knowledge we can create a primitive voting system(represented below in database tables):\r\n\r\n            users                                            posts\r\n    --------------------               ------------------------------------------------\r\n    |  id   |   name   |               |  id  |  title  |  body  |  owner  |  score   | \r\n    --------------------               ------------------------------------------------\r\n\r\nSo here we have a pretty normal situation, you have a bunch of user created posts, that contain a title, text body, and an owner.  We could easily allow these posts to be voted upon by adding an up/down vote arrow next to each post in user interface, and then have a view that receives the id of the post and whether it was upvoted or downvoted.  This view would then find the respective post, and would either increment or decrement the score field by 1.  The problems with this system should be pretty obvious, under this system a user would be able to voted for things multiple times, b/c we\'re not tracking who has voted on what post.  It is also a problem, because our users would not be able to see what they have voted on.  So the questions arises, how do you keep track of every single time a user clicks on an up/down vote arrow?  If you think about it, every time someone votes on a piece of content, they are creating a link between their user and that piece of content on the back-end.  So now as we get further into the problem, we can start seeing a many-to-many relationship emerge, b/c every time a vote is made, that aforementioned \"link\" can be represented like this:\r\n\r\n                users_posts\r\n    -----------------------------------\r\n    |  user_id  |  post_id  |  vote  |\r\n    -----------------------------------\r\n\r\nSo every time a user clicks on an arrow, a record is stored in the database that persists that specific user(user_id) voting on a specific post(post_id) in a way that is indicated by the \'vote\' field in some way, either as a string(\'up or \'down\') or a integer(-1 or 1).  I like the number approach better, as you can then sum all of votes for a specific post to arrive at the score of that post.  \r\n\r\nOn a side note, many-to-many relationships, or more specifically an association objects, are incredibly common for solving problems such as these, where you have a number of \"links\" between objects being made.  The difference between a many-to-many relationship and an association object patterns are that in SQLAlchemy, a many-to-many relationship uses a \"secondary\" table in order to relate two tables while an association object uses another model that inherits from the Base.  A standard many-to-many ends up looking something like this:\r\n\r\n    UserGroupModel = Table(\'users_groups\', Base.metadata,\r\n                           Column(\'user_id\', Integer, ForeignKey(\'users.id\'), primary_key=True),\r\n                           Column(\'group_id\', Integer, ForeignKey(\'groups.id\'), primary_key=True)\r\n    )\r\n\r\n    class GroupModel(Base):\r\n        __tablename__ = \'groups\'\r\n\r\n        id = Column(Integer, primary_key=True)\r\n        name = Column(String(50))\r\n\r\n        def __init__(self, **fields):\r\n            self.__dict__.update(fields)\r\n\r\n        def __repr__(self):\r\n            return \"<Group(\'%s\', \'%s\')>\" % (self.id,\r\n                                            self.name)\r\n\r\n    class UserModel(Base):\r\n        __tablename__ = \'users\'\r\n\r\n        id = Column(Integer, primary_key=True)\r\n        identifier = Column(String(50))\r\n        password = Column(String(40))\r\n        groups = relationship(GroupModel,\r\n                              secondary=UserGroupModel,\r\n                              backref=\"users\")\r\n\r\n        def __init__(self, **fields):\r\n            self.__dict__.update(fields)\r\n\r\n        def __repr__(self):\r\n            return \"<User(\'%s\', \'%s\')>\" % (self.id,\r\n                                           self.identifier)\r\n\r\nWhile on the other hand, an association object uses a completely separate model, which inherits from the base just like the rest of them, in order to create the relationship.  This opens up the possibility to stick other values on the intermediary model which store extra data about the link.  We\'ll use this concept to store whether a vote is an up/down vote later. One caveat of the association object pattern, however, is that you have to interact with the intermediary model directly and use association proxies, as opposed to it being completely transparent in a standard many-to-many.  You can read more on this topic [here](http://www.sqlalchemy.org/docs/orm/extensions/associationproxy.html?highlight=association%20proxy#simplifying-association-objects).  From the demo code, this is an example of an association object:\r\n\r\n    class ObjectsModel(Base):\r\n        __tablename__ = \'objects\'\r\n        \r\n        id = Column(Integer, primary_key=True)\r\n        score = Column(Integer(100), default=0)\r\n        voted_users = association_proxy(\'users_objects\', \'users\')\r\n    \r\n        def __init__(self, **fields):\r\n            self.__dict__.update(fields)\r\n    \r\n        def __repr__(self):\r\n            return \"<Objects(\'%s\')>\" % (self.id)\r\n    \r\n    class UsersModel(Base):\r\n        __tablename__ = \'users\'\r\n        \r\n        id = Column(Integer, primary_key=True)\r\n        voted_objects = association_proxy(\'users_objects\', \'objects\')\r\n    \r\n        def __init__(self, **fields):\r\n            self.__dict__.update(fields)\r\n    \r\n        def __repr__(self):\r\n            return \"<Users(\'%s\', \'%s\', \'%s\')>\" % (self.id)\r\n    \r\n    class UsersObjectsModel(Base):\r\n        __tablename__ = \'users_objects\'\r\n        \r\n        id = Column(Integer, primary_key=True)\r\n        user_id = Column(Integer, ForeignKey(\'users.id\'))\r\n        object_id = Column(Integer, ForeignKey(\'objects.id\'))\r\n        vote = Column(Integer(1))\r\n        \r\n        users = relationship(UsersModel,\r\n                             backref=\"users_objects\")\r\n        objects = relationship(ObjectsModel,\r\n                               backref=\"users_objects\")\r\n    \r\n        def __init__(self, **fields):\r\n            self.__dict__.update(fields)\r\n    \r\n        def __repr__(self):\r\n            return \"<UsersComments(\'%s\', \'%s\', \'%s\')>\" % (self.user_id,\r\n                                                          self.object_id,\r\n                                                          self.vote) \r\n\r\nFor another example of a use of association objects, recently I made an app that is used for making Dota 2 guides.  In this app, I had a number of users adding items from a list of about 125 into different sections of each guide.  I used a an association object to create a relationship between my \"guide\" model and my \"user\" model each time someone dragged an item into a section of a guide.  This got me to a point where I could see which items were added to which guide; however, I needed to see exactly which section of the guide the item was added to, so I add some metadata to the relationship.  Putting a \"section\" field on the intermediary model allowed me to see exactly which section of the guide the user added the item to.  I tend to always like to use association objects as opposed to many-to-many relationships, as it always gives me to add metadata to the relationship later on.\r\n\r\n\r\n###Pyramid-Specific Stuff\r\nSo now we know how the data is represented in the database, and how we keep track of each user voting on content. Now let\'s look at the stuff we add to our Pyramid configuration.  Believe it or not, you can get away with only having to add a single route and a single view to your application.  Let\'s check out the route first:\r\n\r\n    config.add_route(\'toggle_vote\', \'/toggle_vote/{user_id}/{object_id}/{vote}\')\r\n\r\nKnowing how it looks in the database, this looks pretty appropriate, right?  Every time a user votes on something, we make this request and pass in the id of the user(could alternately be their username or something), the id of the object(comment, post, article, etc), and the orientation of their vote.  This can be directed to from a link, but the cleaner approach is to spawn an AJAX request each time a user clicks on an up/down arrow, which is the approach I take in the demo.  Either way, once you make a request that matches this route, a view like this is called:\r\n\r\n    class ToggleVoteHandler(object):\r\n        def __init__(self, request):\r\n            self.request = request\r\n            self.here = request.environ[\'PATH_INFO\']\r\n            self.matchdict = request.matchdict\r\n            \r\n        @view_config(route_name=\'toggle_vote\', renderer=\'json\')\r\n        def toggle_vote(self):\r\n            user_id = self.matchdict[\'user_id\']\r\n            object_id = self.matchdict[\'object_id\']\r\n            vote = self.matchdict[\'vote\']\r\n            \r\n            db = self.request.db\r\n            voted_object = db.query(ObjectsModel).filter_by(id=object_id).first()\r\n            if vote==\'up\':\r\n                vote = 1\r\n            elif vote==\'down\':\r\n                vote = -1\r\n            else:\r\n                return {\'status\' : \'unchanged\', \'score\' : voted_object.score}\r\n            \r\n            users_objects = db.query(UsersObjectsModel).filter_by(user_id=user_id,\r\n                                                                  object_id=object_id).first()\r\n            # Vote exists                                                             \r\n            if users_objects:\r\n                if users_objects.vote != vote:\r\n                    users_objects.vote = vote\r\n                    db.flush()\r\n                    status = \'changed\'\r\n                else:\r\n                    db.delete(users_objects)\r\n                    db.flush()\r\n                    status = \'deleted\'\r\n                    \r\n            # Vote doesn\'t exist\r\n            else:\r\n                users_objects = UsersObjectsModel(user_id=user_id,\r\n                                                  object_id=object_id,\r\n                                                  vote=vote)\r\n                db.add(users_objects)\r\n                db.flush()\r\n                status = \'added\'\r\n            \r\n            score = self.calculateScore(voted_object)\r\n            voted_object.score = score\r\n            db.flush()\r\n            return {\'status\' : status, \'score\' : score}\r\n            \r\n        def calculateScore(self, voted_object):\r\n            score = 0\r\n            for users_objects in voted_object.users_objects:\r\n                score += users_objects.vote\r\n            return score \r\n\r\nSo this view pretty much does all of the business logic we have talked about, plus a little extra.  It get\'s the user_id, object_id, and the vote through the matchdict, and makes sure that the vote is a valid value of \'-1\' or \'1\'.  Then it tries to find out if the user has voted on this specific object before.  If they have, it then further checks if the vote is of the same orientation or not, and either changes the vote or deletes the relationship(if the user clicks on the same orientation a second time, they are trying to remove their vote) respectively.  If they haven\'t voted on this object before, the view creates a link between the user and the object with the specified vote orientation.  Lastly all of the votes related with the object are summed and the score is return in a JSON object, as well as a status string that I included for the front-end.  So this process should be fairly straight forward, once you get the hang of the way the data is managed in the database, as the view is the element of the application that is actually doing all of the heavy lifting to store/correct the data.  Now all that is left is the front-end.\r\n\r\n###Let\'s Get the Client Talking To Us\r\nThe last step in getting this system to work, is we need a way to get the client to tell us when a user clicks on a up or down arrow.  As I mentioned before, you could make each arrow an anchor tag to the appropriate view, but this wouldn\'t provide for a very responsive interface.  So what I have done is, added an onclick event to the up/down arrows, which sends a request to the Pyramid app which is handled by the \'toggle_vote\' view.  Here is what the voting buttons look like next to each post in the demo.\r\n\r\n    <div class=\"vote\">\r\n        <div class=\"${up}\" onClick=\"javascript: toggle_vote(this, ${user_id}, ${object.id}, \'up\');\"></div>\r\n        <div class=\"${down}\" onClick=\"javascript: toggle_vote(this, ${user_id}, ${object.id}, \'down\');\"></div>\r\n    </div>\r\n\r\nThis calls a javascript function called, appropriately, \'toggle_vote\', which does all of the interfacey changes once a vote is made.  It looks like this:\r\n\r\n    toggle_vote = function(node, user_id, object_id, vote) {\r\n        object_vote = node.parentNode;\r\n        object = object_vote.parentNode;\r\n            \r\n        removeActiveClass = function(node) {\r\n            index = node.className.indexOf(\" active\");\r\n            node.className = (index != -1) ? node.className.substring(0, index) : node.className;\r\n        };\r\n        \r\n        addActiveClass = function(node) {\r\n            node.className = node.className + \" active\";\r\n        };\r\n        \r\n        removeAllActiveClasses = function(parent) {\r\n            $.each(parent.children, function(index, child) {\r\n                removeActiveClass(child); \r\n            });\r\n        };\r\n    \r\n        setScore = function(score) {\r\n            object_score = undefined;\r\n            $.each(object.children, function(index, child) {\r\n                if (child.className == \"score\") {\r\n                    object_score = child;   \r\n                }\r\n            });\r\n            object_score.innerHTML = String(score);\r\n        };\r\n        \r\n        toggleVoteCallback = function(data) {\r\n            if (data.status != \"unchanged\") {\r\n                if (node.className.indexOf(\"active\") != -1) {\r\n                    removeAllActiveClasses(object_vote);\r\n                }\r\n                else {\r\n                    removeAllActiveClasses(object_vote);\r\n                    addActiveClass(node);\r\n                }\r\n            }\r\n            \r\n            setScore(data.score);\r\n        };\r\n            \r\n    	$.ajax({\r\n	    type: \"GET\",\r\n    	    url: \"/toggle_vote/\" + user_id + \"/\" + object_id + \"/\" + vote,\r\n            success: toggleVoteCallback\r\n        });\r\n    };\r\n\r\nI\'m sure their is an easier way to do some of these things with some jQuery magic unknown to me, but essentially what it does, is it first sends a AJAX GET request to the \'toggle_vote\' view that we talked about previously.  Then according to the status string, it changes the up/down arrows to either be inactive or active, which translates to either being of the \'active\' class or not.  Lastly it takes the current score of the object(the sum of all of its votes) and updates the part of the interface that displays the score.  I decided on going with this method, as it ensures an updated value of the score; however, this also means that if a user votes on something at the same time as another user, one of them will see the score go up by two, which is not a desired outcome and might confuse people, so something to keep in mind. So that\'s that. The full process of adding social voting to your site.\r\n\r\n**Note On Security:  This demo is not exactly secure, because we can\'t verify that a request is coming from the user specified as the \'user_id\'.  So to improve this example, we could add a CSRF check or something to verify that it truly is the user voting on an object.  That could be for another day.','2011-12-05','2011-12-05 16:14:35','2011-12-05 19:11:33'),(29,'Back For More - GSOC Round Two','After GSOC last year, I decided that I definitely wanted to partake when the opportunity rolled around this year.  I talked with a few individuals in the Pyramid community about this during Pycon, and later on in the mailing lists.  After a few weeks, we got the ball rolling and a few ideas were thrown around for a possible project.  The first idea that came up involved modifying the pyramid debug toolbar to include some new introspection features, by leveraging a relatively new tool called [Pyrasite](http://pyrasite.readthedocs.org/en/latest/index.html).  After a few discussions, we came to the conclusion that although this new feature would be really cool, we would passing up a golden opportunity to get a long awaited perk rolled out for pyramid.  What is this feature you might ask?  Wait for it.  A WINDOWS INSTALLER!  And better Windows support in general. I know, I know, most of us are linux/mac hackers/elitists, and wouldn\'t really give Windows a second thought.  The fact of the matter is, is that there a number of Windows Python users.  We would be completely ignoring a huge potential user base if we continued to only consider the user experience of linux/mac users.  So this brings us to the present.\r\n\r\nI have been tasked with creating a Windows installer primarily in the first half of GSOC, and then during the second half, I will explore potential ways to make the Windows experience even better.  I am extremely new to development for the win32api, and had to do some research to even have a clue of where to begin.  I discovered that there are a number of tools for creating installers.  The major ones are [NSIS](http://nsis.sourceforge.net/Main_Page), Windows Installer, and Install Shield.  NSIS seemed like the best option, as it is the only one that was open source, and it was even actively used by large companies such as Google and Yahoo.  After reading a few blog posts about it, however, I discovered that it had one major flaw.  It\'s scripting language.  A number of users reported that it was an absolute nightmare to do anything that wasn\'t already packaged in the tool.  So basically....if you need to do something beyond the scope of the 10 or so widgets, you\'re going [to have a bad time](http://www.quickmeme.com/meme/3p2xn5/).  NSIS isn\'t alone either, most users of any of these major installer-creation tools complained that the scripting languages were clunky and hard to use.\r\n\r\nI have come to the conclusion that I will be far better of if I write my own installer from scratch in C++.  This will give me the added benefit of improving my C++ skills, learning the win32api, and making an incredibly custom installer for the Pyramid community.  I will be able to customize the look and feel of the installer, and give Pyramid a very cool \"cover.\"  [This](http://blog.kowalczyk.info/article/8nqb/Writing-a-custom-installer-for-Windows-software.html) blog post was what really convinced me that this task is definitely possible.  At first I was really skeptical of this project, as I\'m not an avid Window\'s user for anything besides gaming, but now I am actually pretty psyched to get started!  What do people think about my course of action?  E-mail me.','2012-05-02','2012-05-02 03:31:33','2012-05-02 03:35:39'),(30,'To Take the Py Road, or to Learn the Win32 Api...','So I have been doing some intense research on the topic of this windows installer, and there are three clear options at hand for creating a windows installer for Pyramid.  The first method I have already laid out pretty clearly in my last blog post, this being to simply use a pre-existing framework such as NSIS.  I have already pretty much eliminated this option, as it will lead to an unoriginal and likely unmaintainable installer.  However, on second thought this might be a good immediate option, in order to get a windows installer out there right away and on the website.  The second option is by far the most work intensive of the three, but it would be the most interesting(in my opinion) and would result in the largest educational payoff(once again, in my opinion).  This option entails learning as much of the Win32 api as I will need, and making the installer from scratch in C++.  To be honest, I like this option the most.  Lastly, the third method of creating the installer is a little harder than the first, but far less hard than the second.  It will involve writing the installer in Python using wxPython, Tkinter, pyGTK, or PythonWin.  This is by far the most maintainable route to take, b/c other members of the community could potential maintain it with me after the program.  I also am already proficient in Python, so I wouldn\'t have to gain experience in C++(I have done C++ work in the past, just not a great deal of it).  So those are the three options, I\'ve told you my favorite, but it might very well be impractical.  Tell me what you think.','2012-05-22','2012-05-22 02:00:59','2012-05-22 02:04:23'),(31,'Steps for Getting Pyramid Working On Windows','I was asked by the Pyramid community to go through the installation process of Pyramid, and do a few of the tutorials, to see how the user experience is on Windows.  I have done so, and here are my results.  Firstly, these are the steps I had to take to install Pyramid on Windows:\r\n\r\n1.  Install a python interpreter from the python [website](http://python.org/download/).\r\n2.  Install the [pywin32](http://sourceforge.net/projects/pywin32/files/) Windows extensions.  For some reason I couldn\'t get these extensions to install while using Python 2.7.  It was only until I switched to Python 2.6 that everything installed correctly.\r\n3.  Add C:\\\\\\\\Python26 to your PATH by changing your environment variables.\r\n4.  Download the [ez_setup.py file](http://peak.telecommunity.com/dist/ez_setup.py).  Run:\r\n\r\n        C:\\> C:\\Python26\\python ez_setup.py\r\n\r\n5.  Use easy_install to install virtualenv, activate that environment, and then easy_install Pyramid.\r\n\r\nIt was that simple.  Nothing else was required.  I was able to do two of Pyramid\'s tutorials in exactly the same way that I would develop on OSX, without any snags.  There is one minor step that I left out of this process that I would like to consider automating in our Windows installer, the creation of Pyramid scaffold.  I think that the installer would do nicely with an optional section at the end that allows you to place a rendered Pyramid scaffold somewhere on your system, and then opens up a command prompt in the same directory.  \r\n\r\nSo after experiencing what it is like to develop using Pyramid on Windows, I think I\'m well equipped to create some basic mockups of what I want the installer to look like.  Check out the following pics of some possible designs:\r\n\r\n![Flowchart](http://i.imgur.com/0sYR2.jpg)\r\n\r\nI left out the fact that there would be skip buttons on the \"Create a Virtualenv\" and \"Create a Scaffold\" pages.','2012-05-25','2012-05-25 03:19:47','2012-05-30 03:53:32'),(32,'Moving Right Along....','So the last couple weeks have been incredibly busy.  Between work and my latest endeavor known as clusterflunk.com, GSOC has been taking the backburner.  Realizing this, I have been taking this entire week to focus solely on GSOC.  Throughout the last week, a number of things have happened.  The first being that I found this [blog post](https://github.com/blog/1151-designing-github-for-windows), and was really quite inspired by the product they created.  The post was written by the guys at github.com, about their latest release of Github for Windows.  In the post, they talk about their design process, and go into depth about what technologies they used for creating the actual application and its unique graphical style.  It turns out they used WPF(Windows Presentation Foundation) and Expression blend for the most part.  I decided that I really wanted to use the same technologies for the Pyramid site manager app that is part of my GSOC specification.  So I got right to work learning WPF, by buying two books related to the topic, \"WPF Unleashed 4\" and \"Sam\'s Teach Yourself WPF in 24-hours.\"  I bought the second after the first one proved to be a little long(and admittedly boring), but still a great definitive resource on the topic.\r\n\r\nI even got into contact with the two developers of Github for Windows, and started asking them specific questions about WPF and Expression Blend.  Some of the major ones are documented below.\r\n\r\n###What windows installer did you use to distribute your app?\r\nWe ended up using ClickOnce as the installer technology which has its\r\nbenefits/drawbacks. We did some very specific things with the\r\ntechnology to make updates happen without user intervention. ClickOnce\r\nworks pretty well, but based on a couple of deficiencies, we\'ve\r\nstarted working on a new installer technology that we hope to use in a\r\nfuture version of the app. You can checkout the work in progress here:\r\n[https://github.com/xpaulbettsx/nsync](https://github.com/xpaulbettsx/nsync).\r\n\r\n###So you designed the user interface first, correct?\r\nI definitely work by doing design first. This includes look and feel\r\nas well as interaction. I\'ll often prototype designs without major\r\nunderlying functionality just to get a feel for what is possible and\r\nfor how much work certain things are going to be. You can get too\r\nbogged down in the details of implementation otherwise, and then your\r\ndesign suffers because you start doing things b/c they are easy or\r\nknown instead of doing things that are innovative. Simple design often\r\nrequires complex implementation and you don\'t want to shy away from\r\nthis.\r\n\r\n###Did your knowledge of WPF affect the design, or did you design it first, and worried about how to do it in WPF second?\r\nWould design first. There is very little that you can\'t do with WPF\r\nthese days.\r\n\r\nSo after hearing from them, I was even more set on doing things in a similar manner.  I then talked to Chris about what I had been looking into over the last few days, and he had some critiques that in the end made a lot of sense to me and made my reconsider a lot of decisions.  He mentioned that ClickOnce could only be used to distribute .NET applications, and could not bundle Python in any way, so that would obviously not work for my project, as I need to distribute Python along with Pyramid.  Secondly,  he mentioned that although WPF is the major Microsoft-backed method of creating software, it is not the easiest to learn, nor is it cross-platform what-so-ever.  This would mean that few members of the Pyramid community would be able to help me maintain the gui once it is created if I were to use WPF, and I also wouldn\'t be able to have any hope of getting this thing to run on OSX or Linux.  So I took Chris\'s advice and started on just getting the installer rolled out using Innosetup, which has proven to be easy enough.  I have the source [here](https://github.com/jayd3e/kiya).  I have a few bugs to work out regarding eggs not getting bundled correctly in the setup file, so I\'ll look into those problems later tonight.  Plan on just continuing to get feedback about the installer until it meets everyone\'s standards.\r\n\r\n','2012-06-13','2012-06-13 15:07:35','2012-06-13 15:21:23'),(33,'Two Week Sprint Begins','So I have to be honest, at this point in GSOC, I am not in great condition.  I have been focusing heavily on my startup and my job with surveymonkey.com, and my time and focus has been pretty stretched.  GSOC has definitely been taking the back burner.  This is stopping tonight.  Tonight begins a two week long development sprint.  I have a chosen path for the project, and I\'m going to act on it with complete dedication. I will still have my normal job of course, but every night will be dedicated to making this site admin tool/installer.  I will also be blogging every night to keep myself focused, and properly document the sprint.  You can also follow my progress on the official repo [here](https://github.com/jayd3e/kiya).\r\n\r\n###Chosen Path\r\nI have decided to use PyGTK for the site admin interface.  Last night I got started on experimenting with PyGTK, and made a basic app.  I then used py2exe and innosetup to create a single file installer for the app.  Everything worked out great, and in the end I was very pleased with the process.  So I have decided these are the technologies I will be using.\r\n\r\n###Tonight\'s Work\r\nTonight I will come up with a quick \"first pass\" design document.  It will facilitate the ability to add, remove, serve, and open Pyramid projects.  I will be attempting to create the interface using PyGTK.','2012-06-26','2012-06-26 01:36:18','2012-06-26 01:42:32');
/*!40000 ALTER TABLE `posts` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2012-07-27  0:19:10
